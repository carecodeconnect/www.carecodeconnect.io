[
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "A Mindset for the Anthropocene\n\n\n\nA Mindset for the Anthropocene\n\n\nThis project involved network visualisation of resources for sustainable futures: A Mindset for the Anthropocene\n\n\nApp Store Review Analyser\nStreamlit app provides insightful analysis of App Store reviews for any given app. By inputting the App Store URL, users can explore trends, sentiments, and summaries of reviews within a specified date range.\nThe app is available for use with OpenAI GPT-3.5 or GPT-4 API here: App with OpenAI or with DistilBart here: App with BART.\nClick here for the GitHub repositories for OpenAI API and DistilBart\n\n\nAutomatic Customer Review Analyser\nThis project uses Machine Learning to turn customer reviews into actionable insights. It uses classification, implementing Linear Classifiers (Perceptron, Average Perceptron, and Pegasos Algorithm), to classify the reviews as ‘positive’ or ‘negative’. Focusing on Amazon’s food product reviews, this system employs sentiment analysis to categorize feedback, providing an automated, efficient, and scalable approach to handling customer reviews.\nClick for GitHub repository\n\n\nBuilding a Data Science Server on Raspberry Pi\n\n\n\n\ngraph TD;\n    A[Raspberry Pi 5] --&gt;|Hosts| B[Ubuntu Server];\n    B --&gt; C[SSH for Remote Access];\n    B --&gt;|Web Server| D[NGINX];\n    D --&gt; E[UFW Firewall];\n    D --&gt;|SSL Encryption| F[SSL Certificates];\n    B --&gt;|Publishing & Presentation| G[Quarto];\n    G --&gt;|Content Editing| H[Visual Studio Code];\n    G --&gt;|Version Control| I[Git with GitHub];\n    H --&gt;|Remote Development| J[VS Code Remote Development Extension];\n\n    style A fill:#f9f,stroke:#333,stroke-width:2px\n    style B fill:#fcf,stroke:#333,stroke-width:2px\n    style C fill:#cff,stroke:#333,stroke-width:2px\n    style D fill:#fcf,stroke:#333,stroke-width:2px\n    style E fill:#cff,stroke:#333,stroke-width:2px\n    style F fill:#fcf,stroke:#333,stroke-width:2px\n    style G fill:#cff,stroke:#333,stroke-width:2px\n    style H fill:#fcf,stroke:#333,stroke-width:2px\n    style I fill:#cff,stroke:#333,stroke-width:2px\n    style J fill:#fcf,stroke:#333,stroke-width:2px\n\n\n\n\n\n\nA tutorial to build a self-hosted data science server on a Raspberry Pi 5.\n\n\nComing Soon\nThe following projects are work-in-progress and coming soon!\n\nJhāna AI: Meditation Teacher: a multi-modal voice assistant for personalised meditation in deep states of tranquility. Combines cutting-edge open source HuggingFace Transformer architectures for Natural Language Processing (NLP) with LangChain combined with insights from Conversation Analysis.\nJob Seeker: automates the process of finding a job.\nLease Linker: automates the process of finding accommodation.\nWine Review Analyser: employs pandas, scikit-learn, and sentiment analysis to model wine sales and reviews.\n\n\n\nData Visualisation with D3\nA work-in-progress sandbox of a D3 app deployed with GitHub Projects.\nClick for GitHub repository\n\n\nDigit Recogniser\nA deep learning neural network which recognises handwritten digits. It develops a Multi-Level Perceptron (MLP) model for handwritten digit recognition using the MNIST dataset, implemented entirely by hand using Python’s NumPy library. The project emphasizes Object-Oriented Programming (OOP) for a modular and clear code structure.\nClick for GitHub repository\n\n\nMapMind (Part I): Mapping the Mindfulness Movement\n\n\n\nHeatmap of mindfulness teachers and mindfulness teaching in the U.K.\n\n\nThe MapMind project studied the people at the forefront of the mindfulness movement. The analysis in this report utilized the Machine Learning algorithm K-Means clustering to explore the urban concentrations of mindfulness teaching, demonstrating its effectiveness in handling nationwide geospatial datasets.\n\n\nMapMind (Part II): Who Are Mindfulness Teachers?\n\n\n\nThe project studied the people at the forefront of the mindfulness movement\n\n\nIn Part II of the MapMind project, we explore the demographics of mindfulness teachers. We use Exploratory Data Analysis (EDA) and data visualisation to reveal the hidden patterns in the survey data using descriptive statistics.\n\n\nMapMind (Part III): Digital Divides: Mindfulness Teaching & Technology\n\n\n\nThe project studied digital divides in mindfulness teaching\n\n\nThe final part of the MapMind project looks at how mindfulness teachers relate to technology, and uses predictive modeling using Chi-Squared tests and logistic regression to identify the factors that predict whether mindfulness teachers engage in online teaching based on several features, including gender, years of teaching experience, whether they hold a management position, and their nationality.\n\n\nPalmer Penguins\nStreamlit app using the Palmer Penguins dataset. The Palmer Penguins dataset is a popular dataset for data exploration and visualization. We use the dataset to create a simple Streamlit app that includes a bar chart, scatter plot, violin plots, and a YouTube video.\nClick for GitHub repository\n\n\nMovie Recommender with Ridge Regression\nThis project provides accurate movie recommendations based on user preferences and historical ratings data. The recommender uses Ridge regression to learn to predict ratings based on a substantial amount of data. The results indicate a relatively low average deviation of the predicted ratings from the actual ratings, demonstrating the model’s effectiveness in making accurate predictions.\nClick for GitHub repository\n\n\nRichter’s Predictor: Modeling Earthquake Damage\nBased on aspects of building location and construction, this project predicts the level of damage to buildings caused by the 2015 Gorkha earthquake in Nepal. Our team of data scientists from Data Science Retreat developed a model to predict the level of damage to the buildings. We used a variety of machine learning models, including Logistic Regression, Gradient Boosting, XGBoost, and Neural Networks. This project uses data provided by DrivenData. The data was collected through surveys by Kathmandu Living Labs and the Central Bureau of Statistics, which works under the National Planning Commission Secretariat of Nepal. This survey is one of the largest post-disaster datasets ever collected, containing valuable information on earthquake impacts, household conditions, and socio-economic-demographic statistics.\nClick for GitHub repository\n\n\nWeather Analysis Toolkit\n\n\n\nPredicting the weather\n\n\nThis project is a toolkit for fetching, analyzing, and generating reports on weather data. It assesses forecast accuracy over time and understanding weekly weather statistics. This version of the toolkit reports today’s weather and the forecast weather for tomorrow at noon in Berlin.\nClick for GitHub repository"
  },
  {
    "objectID": "projects/mapmind/mapmind_mapping.html",
    "href": "projects/mapmind/mapmind_mapping.html",
    "title": "MapMind (Part I): Mapping the Mindfulness Movement",
    "section": "",
    "text": "The MapMind project studied the people at the forefront of the mindfulness movement. We studied the popularity, nature, teaching, and societal influence of mindfulness. We focused on the people, places, and practices within the mindfulness movement, especially teachers. The project provides insights into the untold stories and hidden histories of the people leading the mindfulness phenomenon. A central aim of the project is to enhance the accessibility and impact of mindfulness teaching in the U.K.\nI was Principal Investigator on the project and led a core team of 4 researchers over 4 years (2017-2021). We received £227,661 of funding from an independent funding body, The Leverhulme Trust. The project included the first nationwide survey of mindfulness teachers worldwide, and involved participation of 800+ users, and 60+ stakeholder organizations, networks and centres.\nIn this report, I focus on the following specific research question: where is mindfulness being taught?\nThe analysis in this report utilized the machine learning algorithm of K-Means clustering to explore the urban concentrations of mindfulness teaching, demonstrating its effectiveness in handling large geospatial datasets.\nThis document is interactive, which means you can interact with the maps, by zooming in and out, or selecting the layers to view."
  },
  {
    "objectID": "projects/mapmind/mapmind_mapping.html#key-outsights",
    "href": "projects/mapmind/mapmind_mapping.html#key-outsights",
    "title": "MapMind (Part I): Mapping the Mindfulness Movement",
    "section": "Key ‘Outsights’",
    "text": "Key ‘Outsights’\nPart I of the MapMind project showcases the following:\n\nBusiness Relevance: MapMind provides essential data-driven insights for mindfulness businesses in the wellness and health sectors, as well as educational and mental health institutions. It enables these entities to pinpoint areas for mindfulness program implementation, understand regional preferences, and customize their services. The project also aids policymakers in appreciating the role of mindfulness in mental health and wellbeing, guiding funding and support decisions.\nTechnical Skills: The project demonstrates advanced technical skills, employing Python and related libraries for data collection, analysis, and GIS mapping. These technical aspects highlight the project’s robust foundation in modern data science practices, making it a notable example of how programming and analytical skills can be applied to socially significant issues.\nValue Added: MapMind adds significant value by highlighting aspects of the mindfulness movement that are often overlooked. It offers a comprehensive overview of the mindfulness teaching landscape, serving as a valuable resource for researchers, practitioners, and enthusiasts to explore trends, identify gaps, and recognize opportunities.\n\n\n\nCode\n# Load Python libraries\nimport os\nimport json\nimport optuna\nfrom IPython.display import display\nimport requests\nfrom requests.exceptions import RequestException\nimport time\n\nimport pyreadstat\nimport statsmodels.api as sm\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom plotly import graph_objs as go\nimport plotly.express as px\nfrom scipy.stats import chi2_contingency\nfrom prettytable import PrettyTable\nfrom scipy.stats import f_oneway\nimport statsmodels.formula.api as smf\n\nimport nltk\nimport sklearn\nfrom sklearn.cluster import KMeans\nimport xgboost\n\nimport geopandas as gpd\nfrom shapely.geometry import Point\nimport folium\nfrom folium.plugins import HeatMap\n\n\n\n\nCode\n# Load data\nsurvey = pd.read_spss(\"data/mm_survey_recoded-all-main_SPSS.sav\")\n\n# Rename columns\nrename_dict = {\n    'Q6.1': 'age',\n    'Q6.2': 'gender',\n    'Q6.3': 'sexuality',\n    'R6.4': 'ethnicity',\n    'Q6.5': 'disability',\n    'R2.25': 'technology',\n    'Q7.2': 'website',\n    'Q2.13': 'online_teaching',\n    'Q2.14': 'online_n',\n    'Q2.10': 'year_started',\n    'R6.6': 'formal_education',\n    'Q6.7': 'prof_qual',\n    'R6.7_3': 'profession',\n    'Q3.7': 'supervise_emp',\n    'Q3.5': 'employment_other_type',\n    'Q3.6': 'job_title',\n    'Q2.23': 'trained',\n    'Q2.24': 'trained_n',\n    'R2.6_1': 'advocacy',\n    'R2.6_2': 'business_entrepreneurial',\n    'R2.6_3': 'management',\n    'R2.11': 'courses_in_year',\n    'Q2.12': 'clients_taught',\n    'Q2.15': 'independent',\n    'R2.16': 'nations',\n    'R2.17': 'region_england',\n    'R2.18': 'region_wales',\n    'R2.19': 'region_scotland',\n    'R.2.20': 'region_ireland',\n    'R2.22': 'area',\n    'R.2.21': 'contexts'\n}\n\nsurvey = survey.rename(columns=rename_dict)\n\n# Convert columns to categorical types where appropriate\ncategorical_columns = [\n    'age', 'gender', 'sexuality', 'ethnicity', 'disability', 'technology', 'website',\n    'online_teaching', 'online_n', 'formal_education', 'prof_qual', 'profession',\n    'supervise_emp', 'employment_other_type', 'trained', 'trained_n', 'advocacy',\n    'business_entrepreneurial', 'management', 'courses_in_year', 'clients_taught',\n    'independent', 'nations', 'region_england', 'region_wales', 'region_scotland',\n    'region_ireland', 'area', 'contexts'\n]\n\nfor col in categorical_columns:\n    survey[col] = pd.Categorical(survey[col])\n\n# Convert 'job_title' to string\nsurvey['job_title'] = survey['job_title'].astype(str)\n\n# Convert 'year_started' to numeric, handling non-numeric values\nsurvey['year_started'] = pd.to_numeric(survey['year_started'], errors='coerce')\n\n# Create survey_tidy DataFrame\nsurvey_tidy = survey.copy()\n\n# Save survey_tidy as a pickle file\nsurvey_tidy.to_pickle(\"data/survey_tidy.pkl\")\n\n# Optional print statements for verification\n#print(\"Renamed columns:\", survey_tidy.columns)\n#print(\"\\nData types of columns:\", survey_tidy.dtypes)\n#print(\"\\nFirst few rows of the DataFrame:\", survey_tidy.head())\n#print(\"\\nUnique values in categorical columns:\")\n#for col in categorical_columns:\n#    print(f\"{col}: {survey_tidy[col].unique()}\")\n\n\n\n\n\nHeatmap of mindfulness teachers and mindfulness teaching in the U.K."
  },
  {
    "objectID": "projects/mapmind/mapmind_mapping.html#research-methods-technical-tools",
    "href": "projects/mapmind/mapmind_mapping.html#research-methods-technical-tools",
    "title": "MapMind (Part I): Mapping the Mindfulness Movement",
    "section": "Research Methods & Technical Tools",
    "text": "Research Methods & Technical Tools\nWe adopted a mixed-methods design using quantitative and qualitative methods.\nOur data collection methods included:\n\nNationwide online survey with 768 participants\n82 in-depth online interviews\n4 online discussion groups\nFieldwork at 28 settings across the U.K. - both online and off-line - from small classes to large-scale public events\n\nThe project involved rigorous ethical reviews, including General Data Protection Regulation (GDPR).\nThe following sections engage in data tidying, exploratory data analysis, followed by statistical analysis.\nThe following Python libraries and statistical tests were used in the report.\n\nData Analysis\n\nPandas:\n\nHandles DataFrame operations such as loading, cleaning, and processing survey data.\n\nScipy:\n\nProvides tools for scientific and technical computing, including statistical functions for data analysis.\n\nPrettyTable:\n\nGenerates simple ASCII tables, useful for displaying data in tabular format.\n\nANOVA (Analysis of Variance):\n\nA statistical method, often implemented using libraries like scipy or statsmodels, to compare means among different groups.\n\nK-Means Clustering:\n\nA method of vector quantization, commonly used for cluster analysis in data mining.\n\nNumpy:\n\nFundamental package for scientific computing with Python, offering support for large, multi-dimensional arrays and matrices.\n\nStatsmodels:\n\nProvides classes and functions for estimating statistical models and conducting statistical tests.\n\nRe (Regular Expressions):\n\nUsed for pattern matching and parsing text data, such as extracting information from survey responses.\n\nRequests:\n\nEnables HTTP requests to external APIs, useful for gathering additional data or interacting with web services.\n\nTime:\n\nUsed to handle time-related tasks, like introducing delays in API requests.\n\n\n\n\nGeospatial Analysis\n\nFolium:\n\nCreates interactive maps to visualize geographic data, such as locations of training providers.\n\nFolium Heatmap Plugin:\n\nAn extension for Folium to create heatmaps, useful for representing density of data points geographically.\n\nGeoPy:\n\nPerforms geocoding and reverse geocoding using services like Nominatim.\n\nNominatim (via GeoPy):\n\nA tool for geocoding, converting an address into geographic coordinates.\n\nShapely:\n\nManages and manipulates geometric shapes, useful in geospatial analysis.\n\nGeoPandas:\n\nExtends the functionalities of Pandas to allow spatial operations on geometric types.\n\n\n\n\nPlotting\n\nMatplotlib:\n\nA plotting library for creating static, animated, and interactive visualizations in Python.\n\nSeaborn:\n\nA visualization library based on Matplotlib, providing a high-level interface for drawing attractive statistical graphics.\n\nPlotly Express:\n\nA high-level interface for creating interactive and aesthetically pleasing plots and charts."
  },
  {
    "objectID": "projects/mapmind/mapmind_mapping.html#mapping-mindfulness-training-providers",
    "href": "projects/mapmind/mapmind_mapping.html#mapping-mindfulness-training-providers",
    "title": "MapMind (Part I): Mapping the Mindfulness Movement",
    "section": "Mapping Mindfulness Training Providers",
    "text": "Mapping Mindfulness Training Providers\nWe asked our participants which recognised provider they received their main training to teach mindfulness.\nThis code performs data manipulation and visualization to analyze mindfulness training providers. Using Pandas for data handling, it loads, renames, and filters a dataset, focusing on the training_providers column. Key data manipulations include replacing specific entries and filtering out irrelevant data. Matplotlib is then used to plot the frequency of each provider in a horizontal bar chart. The results indicate that the top three mindfulness training providers are ‘Centre for Mindfulness Research and Practice, Bangor University’ (135 instances), ‘Breathworks’ (96 instances), and ‘Mindfulness Association’ (40 instances), showcasing their prevalence in the dataset.\n\n\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load the modified DataFrame\nsurvey = pd.read_pickle('data/tidied_survey.pkl')\n\n# Rename the column\nsurvey.rename(columns={'R2.4_9': 'training_providers'}, inplace=True)\n\n# Select the renamed column\ntraining_providers = survey['training_providers']\n\n# Rename 'Bangor' to 'Centre for Mindfulness Research and Practice, Bangor University'\ntraining_providers = training_providers.replace('Bangor', 'Centre for Mindfulness Research and Practice, Bangor University')\n\n# Filter out NAs (empty strings)\ntraining_providers = training_providers[training_providers != '']\n\n# Calculate frequency counts\nfrequency_counts = training_providers.value_counts()\n\n# Remove entries with 0 frequency (this will exclude 'Not applicable' and 'Other' if they have 0 counts)\nfrequency_counts = frequency_counts[frequency_counts &gt; 0]\n\n# Plot the frequencies with switched axes\nplt.figure(figsize=(10, 6))\nfrequency_counts.plot(kind='barh')  # 'barh' for horizontal bar plot\nplt.title('Frequency of Mindfulness Training Providers')\nplt.ylabel('Training Provider')\nplt.xlabel('Frequency')\nplt.gca().invert_yaxis()  # Invert y-axis to have the highest frequency on top\nplt.show()\n\n\n\n\n\nThis code integrates data processing, geocoding, and mapping to visualize the distribution of mindfulness training providers. The code processes data from a DataFrame, calculating the frequency of each training provider. It maps provider names to addresses and uses regular expressions to extract UK postcodes. For geolocating these postcodes, the script utilizes the api.postcodes.io service, fetching latitude and longitude data for each U.K. postcode. Folium is then used to plot these locations on a map, with circle markers whose sizes correspond to the frequency of each provider. The UMass Centre for Mindfulness is given special treatment with predefined coordinates. Finally, the script generates an interactive heatmap, illustrating the geographical spread and prevalence of mindfulness training centers across various locations.\n\n\nCode\nimport pandas as pd\nimport folium\nimport requests\nimport re\nimport time\nfrom geopy.geocoders import Nominatim\nfrom geopy.exc import GeocoderUnavailable, GeocoderTimedOut  # Import these exceptions\n\n# Load the modified DataFrame\nsurvey = pd.read_pickle('data/tidied_survey.pkl')\n\n# Rename and clean the data\nsurvey.rename(columns={'R2.4_9': 'training_providers'}, inplace=True)\ntraining_providers = survey['training_providers']\ntraining_providers = training_providers.replace('Bangor', 'Centre for Mindfulness Research and Practice, Bangor University')\ntraining_providers = training_providers[training_providers != '']\ntraining_providers = training_providers[~training_providers.isin(['Not applicable', 'Other'])]\n\n# Calculate frequency counts\nfrequency_counts = training_providers.value_counts()\n\n# Print the frequency table for verification\n#print(\"Frequency Table:\")\n#print(frequency_counts)\n\naddresses = {\n    \"British Mindfulness Institute\": \"145 – 147 St. John Street, London, EC1V 4PY, United Kingdom\",\n    \"Breathworks\": \"Breathworks CIC/Foundation, 16 - 20 Turner Street, Manchester, M4 1DZ\",\n    \"Centre for Mindfulness Research and Practice, Bangor University\": \"Brigantia Building, Bangor, Gwynedd, LL57 2AS\",\n    \"Exeter University\": \"Washington Singer Building, School of Psychology, University of Exeter, Exeter, EX4 4QG\",\n    \"Gaia House\": \"West Ogwell, Newton Abbot, Devon, TQ12 6EW, England\",\n    \"Integrated Mindfulness Training\": \"145 Radcliffe New Road, Whitefield, Manchester, M45 7RP, England\",\n    \"Mindfulness Association\": \"Boatleys Farmhouse, Kemnay, Inverurie, Aberdeenshire, AB51 5NA\",\n    \"Mindfulness in Schools Project\": \"Bank House, Bank Street, Tonbridge, Kent TN9 1BL\",\n    \"Mindfulness UK\": \"Churchinford, Taunton, Somerset, TA3 7QY\",\n    \"Nottingham Centre for Mindfulness\": \"St. Ann's House, 114 Thorneywood Mount, Nottingham, NG3 2PZ\",\n    \"Oxford Mindfulness Centre\": \"The Wheelhouse, Angel Court, 81 St Clements, Oxford, OX4 1AW\",\n    \"Sussex Mindfulness Centre\": \"Aldrington House, 35 New Church Road, Hove BN3 4AG\",\n    \"UMass Centre for Mindfulness\": \"306 Belmont St, Worcester, MA 01605\",\n    \"University of Aberdeen\": \"King's College, Aberdeen, AB24 3FX\",\n    \"Youth Mindfulness\": \"223, South Block, 60 Osborne St, Glasgow G1 5QH\"\n}\n\n# Initialize a Geocoder instance for Nominatim\ngeolocator = Nominatim(user_agent=\"geoapiExercises\")\n\n# Regex pattern for UK postcodes\npostcode_regex = r'\\b[A-Z]{1,2}[0-9][A-Z0-9]? ?[0-9][A-Z]{2}\\b'\n\n# Function to extract and clean postcode using regex\ndef extract_postcode(address):\n    matches = re.findall(postcode_regex, address, re.IGNORECASE)\n    if matches:\n        return matches[0].replace(\" \", \"\").upper()\n    else:\n        return None\n\n# Function to get geolocation data for a postcode using postcodes.io\ndef get_geolocation(postcode):\n    response = requests.get(f\"http://api.postcodes.io/postcodes/{postcode}\")\n    if response.status_code == 200:\n        return response.json()\n    else:\n        return None\n\n# Initialize Map\nmap_training_centres = folium.Map(location=[54, -2], zoom_start=6)\nlayer_group = folium.FeatureGroup(name=\"Mindfulness Training Centers\")\n\nmax_frequency = frequency_counts.max()\nradius_scale = 10 / max_frequency  # Scale down the radius\n\n# Plotting markers with corrected frequency match and radius\nfor name, address in addresses.items():\n    frequency = int(frequency_counts.get(name, 0))  # Use the correct name to get frequency\n    if frequency &gt; 0:  # Only plot markers for locations with a frequency\n        lat, lon = None, None  # Initialize lat and lon to None\n        # Use the provided coordinates for UMass Centre for Mindfulness\n        if name == \"UMass Centre for Mindfulness\":\n            lat, lon = 42.272889, -71.767704\n        else:\n            postcode = extract_postcode(address)\n            if postcode:\n                geolocation = get_geolocation(postcode)\n                if geolocation:\n                    lat = geolocation['result']['latitude']\n                    lon = geolocation['result']['longitude']\n\n        if lat is not None and lon is not None:  # Check if lat and lon are defined\n            #print(f\"Frequency for {name}: {frequency}, Coordinates: {lat}, {lon}\")\n            folium.CircleMarker(\n                location=[lat, lon],\n                radius=frequency * radius_scale,\n                popup=f\"{name}: {frequency}\",\n                color='red',\n                fill=True,\n                fill_opacity=0.7\n            ).add_to(layer_group)\n            time.sleep(1)\n\n# Add the layer group to the map\nlayer_group.add_to(map_training_centres)\nfolium.LayerControl().add_to(map_training_centres)\nmap_training_centres.save('training_centers_heatmap.html')\nmap_training_centres\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "projects/mapmind/mapmind_mapping.html#mapping-retreat-centres",
    "href": "projects/mapmind/mapmind_mapping.html#mapping-retreat-centres",
    "title": "MapMind (Part I): Mapping the Mindfulness Movement",
    "section": "Mapping Retreat Centres",
    "text": "Mapping Retreat Centres\nWe asked our participants which retreat centres or affiliates they had visited. Our data comprised frequency counts of the participants who had visited the following centres. I processed and analysed the survey data related to retreat centers using the pandas library. I loaded the survey DataFrame from a pickled file and transformed it into a long format, specifically targeting columns associated with retreat centers. The script then filters out entries without visited retreat centers and replaces coded names with actual names using a predefined dictionary. Further, it cleans the data by renaming a column and treating empty strings as missing values. Additionally, the script performs a basic text analysis by counting specific keywords in a text column. Finally, it aggregates this count data with the frequency data of retreat centers into a single table, sorts it, and displays the results.\n\n\nCode\nimport pandas as pd\nimport plotly.graph_objs as go\n\n# Load the modified DataFrame\nsurvey = pd.read_pickle('data/tidied_survey.pkl')\n\n# Melt the DataFrame to long format and filter out non-visited retreat centres\nmelted_survey = survey.melt(value_vars=['Q4.5_1', 'Q4.5_2', 'Q4.5_3', 'Q4.5_4', 'Q4.5_5',\n                                        'Q4.5_6', 'Q4.5_7', 'Q4.5_8'],\n                            var_name='retreat_centre_variable', value_name='retreat_centre')\nmelted_survey = melted_survey[melted_survey['retreat_centre'].notna() & (melted_survey['retreat_centre'] != 0)]\n\n# Mapping for retreat centre names and replace variable names with actual names\nretreat_centre_names = {\n    'Q4.5_1': 'Amaravati Retreat Centre', 'Q4.5_2': 'Gaia House', 'Q4.5_3': 'Manjushri Kadampa Meditation Centre',\n    'Q4.5_4': 'Trigonos', 'Q4.5_5': 'Triratna Buddhist Community', 'Q4.5_6': 'Tibetan Buddhist Centre',\n    'Q4.5_7': 'Vipassana Trust, Dhamma Dīpa', 'Q4.5_8': 'Western Chan Fellowship'\n}\nmelted_survey['retreat_centres'] = melted_survey['retreat_centre_variable'].map(retreat_centre_names)\nfrequency_table = melted_survey['retreat_centres'].value_counts()\n\n# Rename and convert empty strings to pd.NA in the original survey\nsurvey = survey.rename(columns={'Q4.5_9_TEXT': 'retreat_centres_others'})\nsurvey['retreat_centres_others'] = survey['retreat_centres_others'].replace('', pd.NA)\n\n# Count occurrences of specific words or phrases\nkeywords = ['Samye Ling', 'Holy Isle', 'Plum Village', 'Mindfulness Association',\n            'Community of Interbeing', 'Tara Rokpa Centre', 'Breathworks',\n            'Oxford Mindfulness Centre', 'Zenways']\nkeyword_counts = {keyword: survey['retreat_centres_others'].str.contains(keyword, case=False, na=False).sum() for keyword in keywords}\n\n# Convert keyword counts to a DataFrame and combine with frequency table\nkeyword_counts_df = pd.DataFrame(list(keyword_counts.items()), columns=['Keyword', 'Occurrences'])\ncombined_frequency_table = pd.concat([frequency_table, keyword_counts_df.set_index('Keyword')['Occurrences']]).sort_values(ascending=False)\n\n# Create a table with Plotly Express\nfig = go.Figure(data=[go.Table(\n    header=dict(values=[\"Retreat Centre\", \"Frequency\"]),\n    cells=dict(values=[combined_frequency_table.index, combined_frequency_table.values],\n               format=[None, \".0f\"])\n)])\n\n# Add a title to the table\nfig.update_layout(title=\"Retreat Centres\")\n\n# Show the table\nfig.show()\n\n\n\n                                                \n\n\nI then used pandas, folium, requests, re, and geopy to create an interactive map displaying the locations of the retreat centers in the U.K., along with additional centers with predefined coordinates.\nThe Nominatim geocoder from geopy is initialized to convert addresses into geographic coordinates. A regular expression (regex) is used to extract U.K. postcodes from addresses. The requests library is employed to retrieve geolocation data from an external API using these postcodes.\nThe folium library is utilized to create an interactive map centered on the U.K. The map is populated with circle markers representing the retreat centers. These markers are dynamically sized based on the frequency of each center. The frequency data and the coordinates (either from geocoding or predefined) are used to plot the markers.\nAdditionally, a feature group is created in folium to manage these markers, allowing for interactive control over their display. Finally, the map is saved as an HTML file, enabling easy sharing and viewing.\nThis code visualises the geographical data in an interactive manner, and its application here for mapping retreat centers based on survey frequency demonstrates a practical use case in data presentation and geographic analysis.\n\n\nCode\nimport pandas as pd\nimport folium\nfrom folium.plugins import HeatMap\nimport requests\nimport re\nfrom geopy.geocoders import Nominatim\n\n# Initialize a Geocoder instance for Nominatim\ngeolocator = Nominatim(user_agent=\"geoapiExercises\")\n\n# Regex pattern for UK postcodes\npostcode_regex = r'\\b[A-Z]{1,2}[0-9][A-Z0-9]? ?[0-9][A-Z]{2}\\b'\n\ndef extract_postcode(address):\n    matches = re.findall(postcode_regex, address, re.IGNORECASE)\n    if matches:\n        return matches[0].replace(\" \", \"\").upper()\n    else:\n        return None\n\ndef get_geolocation(postcode):\n    response = requests.get(f\"http://api.postcodes.io/postcodes/{postcode}\")\n    if response.status_code == 200:\n        return response.json()\n    else:\n        return None\n\n# Initialize the map centered at a specific location\nmap_retreat_centres = folium.Map(location=[54, -2], zoom_start=6)\nlayer_group = folium.FeatureGroup(name=\"Retreat Centres\")\n\n# Addresses for the UK centers\nuk_addresses = {\n    \"Amaravati Retreat Centre\": \"St Margarets, Great Gaddesden, Hertfordshire, HP1 3BZ, England, United Kingdom\",\n    \"Breathworks\": \"16 - 20 Turner Street, Manchester, M4 1DZ, UK\",\n    \"Gaia House\": \"West Ogwell, Newton Abbot, Devon, TQ12 6EW, England\",\n    \"Manjushri Kadampa Meditation Centre\": \"Conishead Priory, Priory Road (A5087 Coast Road), Ulverston, Cumbria, LA12 9QQ, UK\",\n    \"Oxford Mindfulness Centre\": \"The Wheelhouse, Angel Court, 81 St Clements, Oxford, OX4 1AW, UK\",\n    \"Trigonos\": \"Plas Baladeulyn, Nantlle, Caernarfon, Wales, LL54 6BW\",\n    \"Triratna Buddhist Community\": \"Vajraloka, Tyn-Y-Ddol, Corwen, Denbighshire, LL21 0EN, United Kingdom\",\n    \"Vipassana Trust, Dhamma Dīpa\": \"Pencoyd, St Owens Cross, Hereford HR2 8NG, United Kingdom\"\n}\n\n# Additional centers with predefined coordinates\nadditional_addresses = {\n    \"Holy Isle\": (55.533467, -5.0874746),\n    \"Plum Village\": (44.750513, 0.34150910),\n    \"Samye Ling\": (55.287437, -3.1876922),\n    \"Tara Rokpa Centre\": (-25.743249, 26.349999),\n    \"Western Chan Fellowship\": (51.65083, -3.23167)\n}\n\n# Assuming combined_frequency_table is defined somewhere in your code\nmax_frequency = combined_frequency_table.max()\nradius_scale = 10 / max_frequency\n\n# Function to add a marker to the map\ndef add_marker(lat, lon, name, frequency):\n    folium.CircleMarker(\n        location=[lat, lon],\n        radius=frequency * radius_scale,\n        popup=f\"{name}: {frequency}\",\n        color='red',\n        fill=True,\n        fill_opacity=0.7\n    ).add_to(layer_group)\n\n# Plot UK addresses\nfor centre, address in uk_addresses.items():\n    frequency = int(combined_frequency_table.get(centre, 0))\n    if frequency &gt; 0:\n        postcode = extract_postcode(address)\n        if postcode:\n            geolocation = get_geolocation(postcode)\n            if geolocation:\n                lat = geolocation['result']['latitude']\n                lon = geolocation['result']['longitude']\n                add_marker(lat, lon, centre, frequency)\n\n# Plot additional addresses\nfor name, coords in additional_addresses.items():\n    frequency = int(combined_frequency_table.get(name, 0))\n    if frequency &gt; 0:\n        add_marker(coords[0], coords[1], name, frequency)\n\n# Add the layer group to the map and enable layer control\nlayer_group.add_to(map_retreat_centres)\nfolium.LayerControl().add_to(map_retreat_centres)\n\n# Save the map to an HTML file\nmap_retreat_centres.save('map_retreat_centres.html')\nmap_retreat_centres\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nFinally, I combined the two datasets, training centres and retreat centres, and displayed them on a single interactive map using the Folium library. The code uses various libraries, including Pandas for data manipulation, Folium for map visualization, and Geopy for geolocation services. The code first loads and cleans the training centre data, calculates the frequency of each training centre, and plots them as red markers on the map, with marker sizes scaled based on their frequency. Similarly, it retrieves and plots retreat centre data as blue markers, both for UK addresses and additional coordinates. The resulting map allows users to explore both training and retreat centres with pop-up information, and it includes a layer control for toggling between the two datasets. Finally, the map is saved as an HTML file for further use.\n\n\nCode\nimport pandas as pd\nimport folium\nfrom folium.plugins import HeatMap\nimport requests\nimport re\nfrom geopy.geocoders import Nominatim\nimport time\n\n# Load the modified DataFrame\nsurvey = pd.read_pickle('data/tidied_survey.pkl')\n\n# Rename and clean the data\nsurvey.rename(columns={'R2.4_9': 'training_providers'}, inplace=True)\ntraining_providers = survey['training_providers']\ntraining_providers = training_providers.replace('Bangor', 'Centre for Mindfulness Research and Practice, Bangor University')\ntraining_providers = training_providers[training_providers != '']\ntraining_providers = training_providers[~training_providers.isin(['Not applicable', 'Other'])]\n\n# Calculate frequency counts for training centres\nfrequency_counts = training_providers.value_counts()\n\n# Addresses for the UK training centres\n\naddresses = {\n    \"British Mindfulness Institute\": \"145 – 147 St. John Street, London, EC1V 4PY, United Kingdom\",\n    \"Breathworks\": \"Breathworks CIC/Foundation, 16 - 20 Turner Street, Manchester, M4 1DZ\",\n    \"Centre for Mindfulness Research and Practice, Bangor University\": \"Brigantia Building, Bangor, Gwynedd, LL57 2AS\",\n    \"Exeter University\": \"Washington Singer Building, School of Psychology, University of Exeter, Exeter, EX4 4QG\",\n    \"Gaia House\": \"West Ogwell, Newton Abbot, Devon, TQ12 6EW, England\",\n    \"Integrated Mindfulness Training\": \"145 Radcliffe New Road, Whitefield, Manchester, M45 7RP, England\",\n    \"Mindfulness Association\": \"Boatleys Farmhouse, Kemnay, Inverurie, Aberdeenshire, AB51 5NA\",\n    \"Mindfulness in Schools Project\": \"Bank House, Bank Street, Tonbridge, Kent TN9 1BL\",\n    \"Mindfulness UK\": \"Churchinford, Taunton, Somerset, TA3 7QY\",\n    \"Nottingham Centre for Mindfulness\": \"St. Ann's House, 114 Thorneywood Mount, Nottingham, NG3 2PZ\",\n    \"Oxford Mindfulness Centre\": \"The Wheelhouse, Angel Court, 81 St Clements, Oxford, OX4 1AW\",\n    \"Sussex Mindfulness Centre\": \"Aldrington House, 35 New Church Road, Hove BN3 4AG\",\n    \"UMass Centre for Mindfulness\": \"306 Belmont St, Worcester, MA 01605\",\n    \"University of Aberdeen\": \"King's College, Aberdeen, AB24 3FX\",\n    \"Youth Mindfulness\": \"223, South Block, 60 Osborne St, Glasgow G1 5QH\"\n}\n\n# Initialize a Geocoder instance for Nominatim\ngeolocator = Nominatim(user_agent=\"geoapiExercises\")\n\n# Regex pattern for UK postcodes\npostcode_regex = r'\\b[A-Z]{1,2}[0-9][A-Z0-9]? ?[0-9][A-Z]{2}\\b'\n\n# Function to extract and clean postcode using regex\ndef extract_postcode(address):\n    matches = re.findall(postcode_regex, address, re.IGNORECASE)\n    if matches:\n        return matches[0].replace(\" \", \"\").upper()\n    else:\n        return None\n\n# Function to get geolocation data for a postcode using postcodes.io\ndef get_geolocation(postcode):\n    response = requests.get(f\"http://api.postcodes.io/postcodes/{postcode}\")\n    if response.status_code == 200:\n        return response.json()\n    else:\n        return None\n\n# Initialize Map\nmap_combined = folium.Map(location=[54, -2], zoom_start=6)\ntraining_layer_group = folium.FeatureGroup(name=\"Training Centres\")\nretreat_layer_group = folium.FeatureGroup(name=\"Retreat Centres\")\n\n# Calculate max frequency for scaling radius\nmax_training_frequency = frequency_counts.max()\nmax_retreat_frequency = combined_frequency_table.max()\nradius_scale_training = 10 / max_training_frequency\nradius_scale_retreat = 10 / max_retreat_frequency\n\n# Plotting markers for training centres with corrected frequency match and radius\nfor name, address in addresses.items():\n    frequency = int(frequency_counts.get(name, 0))\n    if frequency &gt; 0:\n        lat, lon = None, None\n        # Use the provided coordinates for UMass Centre for Mindfulness\n        if name == \"UMass Centre for Mindfulness\":\n            lat, lon = 42.272889, -71.767704\n        else:\n            postcode = extract_postcode(address)\n            if postcode:\n                geolocation = get_geolocation(postcode)\n                if geolocation:\n                    lat = geolocation['result']['latitude']\n                    lon = geolocation['result']['longitude']\n\n        if lat is not None and lon is not None:\n            folium.CircleMarker(\n                location=[lat, lon],\n                radius=frequency * radius_scale_training,\n                popup=f\"Training Centre: {name}, Frequency: {frequency}\",\n                color='red',\n                fill=True,\n                fill_opacity=0.7\n            ).add_to(training_layer_group)\n            time.sleep(1)\n\n# Assuming combined_frequency_table is defined somewhere in your code\n# Function to add a marker to the map for retreat centres\ndef add_retreat_marker(lat, lon, name, frequency):\n    folium.CircleMarker(\n        location=[lat, lon],\n        radius=frequency * radius_scale_retreat,\n        popup=f\"Retreat Centre: {name}, Frequency: {frequency}\",\n        color='blue',\n        fill=True,\n        fill_opacity=0.7\n    ).add_to(retreat_layer_group)\n\n# Addresses for the UK centers\nuk_retreat_addresses = {\n    \"Amaravati Retreat Centre\": \"St Margarets, Great Gaddesden, Hertfordshire, HP1 3BZ, England, United Kingdom\",\n    \"Breathworks\": \"16 - 20 Turner Street, Manchester, M4 1DZ, UK\",\n    \"Gaia House\": \"West Ogwell, Newton Abbot, Devon, TQ12 6EW, England\",\n    \"Manjushri Kadampa Meditation Centre\": \"Conishead Priory, Priory Road (A5087 Coast Road), Ulverston, Cumbria, LA12 9QQ, UK\",\n    \"Oxford Mindfulness Centre\": \"The Wheelhouse, Angel Court, 81 St Clements, Oxford, OX4 1AW, UK\",\n    \"Trigonos\": \"Plas Baladeulyn, Nantlle, Caernarfon, Wales, LL54 6BW\",\n    \"Triratna Buddhist Community\": \"Vajraloka, Tyn-Y-Ddol, Corwen, Denbighshire, LL21 0EN, United Kingdom\",\n    \"Vipassana Trust, Dhamma Dīpa\": \"Pencoyd, St Owens Cross, Hereford HR2 8NG, United Kingdom\"\n}\n\n# Additional centers with predefined coordinates\nadditional_retreat_addresses = {\n    \"Holy Isle\": (55.533467, -5.0874746),\n    \"Plum Village\": (44.750513, 0.34150910),\n    \"Samye Ling\": (55.287437, -3.1876922),\n    \"Tara Rokpa Centre\": (-25.743249, 26.349999),\n    \"Western Chan Fellowship\": (51.65083, -3.23167)\n}\n\n# Plot UK retreat addresses\nfor centre, address in uk_retreat_addresses.items():\n    frequency = int(combined_frequency_table.get(centre, 0))\n    if frequency &gt; 0:\n        postcode = extract_postcode(address)\n        if postcode:\n            geolocation = get_geolocation(postcode)\n            if geolocation:\n                lat = geolocation['result']['latitude']\n                lon = geolocation['result']['longitude']\n                add_retreat_marker(lat, lon, centre, frequency)\n\n# Plot additional retreat centre addresses\nfor name, coords in additional_retreat_addresses.items():\n    frequency = int(combined_frequency_table.get(name, 0))\n    if frequency &gt; 0:\n        add_retreat_marker(coords[0], coords[1], name, frequency)\n\n# Add the training and retreat layer groups to the map and enable layer control\ntraining_layer_group.add_to(map_combined)\nretreat_layer_group.add_to(map_combined)\nfolium.LayerControl().add_to(map_combined)\n\n# Save the combined map to an HTML file\nmap_combined.save('combined_map.html')\nmap_combined\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "projects/mapmind/mapmind_mapping.html#mindfulness-teaching-by-nation",
    "href": "projects/mapmind/mapmind_mapping.html#mindfulness-teaching-by-nation",
    "title": "MapMind (Part I): Mapping the Mindfulness Movement",
    "section": "Mindfulness Teaching by Nation",
    "text": "Mindfulness Teaching by Nation\nWe asked our participants which nations they have taught mindfulness.\nThe exploratory data analysis involved a dataset focused on mindfulness teaching locations across various regions and areas. The analysis was conducted using pandas for data handling, plotly.express for interactive visualizations, and prettytable for presenting data in a tabular format. The analysis aimed to identify trends and distributions in mindfulness teaching across different nations (England, Scotland, Wales, Northern Ireland) and distinguish between urban, rural, and mixed areas.\nThe findings revealed a significant concentration of mindfulness teaching in England, predominantly in urban areas. Regional analysis within each nation showed variations, with South East England, Greater London, and South West England being prominent in England. In Scotland, Edinburgh and the Lothians, Glasgow and the Clyde, and Southern Scotland were key regions. South East Wales and North West Wales were notable in Wales, while Northern Ireland showed relatively lower activity in mindfulness teaching, with Derry-Londonderry and Down as the main regions.\nLater, we present a heatmap which shows clusters of mindfulness teaching in specific urban centres of England, Scotland, and Wales.\n\n\nCode\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objs as go\nfrom prettytable import PrettyTable\n\n# Load the modified DataFrame\nsurvey = pd.read_pickle('data/tidied_survey.pkl')\n\n# Create a pie chart for the 'nations' data\nnations_data = survey['nations'].value_counts()\naccessible_palette = ['#1F77B4', '#FF7F0E', '#2CA02C', '#D62728', '#9467BD']  # Color palette\n\n# Create a table with Plotly Express\ntable_fig = go.Figure(data=[go.Table(\n    header=dict(values=[\"Nation\", \"Count\"]),\n    cells=dict(values=[nations_data.index, nations_data.values],\n               format=[None, \".0f\"])\n)])\n\n# Add a title to the table\ntable_fig.update_layout(title=\"Distribution of Mindfulness Teaching by Nation\")\n\n# Create the pie chart\npie_fig = px.pie(names=nations_data.index, values=nations_data.values, \n             title='Distribution of Mindfulness Teaching by Nation',\n             color_discrete_sequence=accessible_palette,\n             hole=0)  # Set hole &gt; 0 for a donut chart\npie_fig.update_traces(textinfo='label+percent', insidetextorientation='radial')\npie_fig.update_layout(showlegend=True)\n\n# Show the table and the pie chart\ntable_fig.show()\npie_fig.show()\n\n\n\n                                                \n\n\n\n                                                \n\n\n\n\nCode\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objs as go\n\n# Load the modified DataFrame\nsurvey = pd.read_pickle('data/tidied_survey.pkl')\n\n# Define a function to plot using Plotly Express and create a Plotly table\ndef plot_and_create_table(data, column_name, title):\n    # Prepare the data: count the occurrences and sort in descending order\n    data_count = data[column_name].value_counts().reset_index()\n    data_count.columns = [column_name, 'count']\n    data_count = data_count.sort_values(by='count', ascending=False)\n\n    # Create the bar chart with Plotly Express\n    fig = px.bar(data_count, y=column_name, x='count', orientation='h', \n                 title=f'Frequency of {title}')\n    fig.update_layout(yaxis={'categoryorder': 'total ascending'})\n\n    # Create the Plotly table\n    table_fig = go.Figure(data=[go.Table(\n        header=dict(values=[column_name, 'Count']),\n        cells=dict(values=[data_count[column_name], data_count['count']],\n                   format=[None, \".0f\"])\n    )])\n\n    # Add a title to the table\n    table_fig.update_layout(title=f'{title} Table')\n\n    return fig, table_fig\n\n# Plot and create tables for each variable in the specified order\nvariables = [\n    ('area', 'Area'),\n    ('region_england', 'Region England'),\n    ('region_scotland', 'Region Scotland'),\n    ('region_wales', 'Region Wales'),\n    ('region_ireland', 'Region Northern Ireland')\n]\n\nfor var, title in variables:\n    bar_chart, table = plot_and_create_table(survey, var, title)\n    \n    # Show both the bar chart and the table\n    bar_chart.show()\n    table.show()"
  },
  {
    "objectID": "projects/mapmind/mapmind_mapping.html#mapping-mindfulness-teaching",
    "href": "projects/mapmind/mapmind_mapping.html#mapping-mindfulness-teaching",
    "title": "MapMind (Part I): Mapping the Mindfulness Movement",
    "section": "Mapping Mindfulness Teaching",
    "text": "Mapping Mindfulness Teaching\nWhen asked to report the three most recent locations where they had provided lessons, we found the provision of mindfulness in the U.K. appears to be surprisingly well distributed across both national and geographic settings.\nThe geographic spread of mindfulness teaching locations was analysed using an interactive heatmap, generated from a total of 1,076 postcodes provided by 639 participants.\nThe first Python code block utilizes the pandas and requests libraries for data manipulation and HTTP requests, respectively. It loads a DataFrame survey_with_postcodes from a pickle file, defines functions to check if a postcode is full and to get its geolocation data using the postcodes.io API. The code iterates through the DataFrame, processes only full postcodes, retrieves their geolocation data, and stores this data in new columns (postcode_1_geo, postcode_2_geo, postcode_3_geo). The geolocated count is tracked and printed, and the updated DataFrame is saved as a pickle file. The outcome is a DataFrame enriched with geolocation data for each full postcode, and a total of 1076 postcodes successfully geolocated.\nThe second code block uses pandas for data handling and folium (along with its HeatMap plugin) for creating interactive maps. It loads two DataFrames from pickle files, representing two different surveys. The script creates a map centered on the UK and generates heat data by extracting geolocation coordinates from both surveys. It then adds this data to a heatmap layer on the map. The script counts and prints the number of non-NA geolocated coordinates from each survey, totaling 1076. The combined heatmap is saved as an HTML file, providing a visual representation of the postcode data from both surveys.\nA limitation of the teaching location heatmaps is that they only show where mindfulness is taught in Britain. The GeoJSON files for geolocating postcodes only included postcodes in Britain.\n\n\nCode\nimport pandas as pd\nimport requests\n\n# Load the data\nsurvey_with_postcodes = pd.read_pickle('data/survey_with_postcodes.pkl')\n\n# Function to get geolocation data for a postcode using postcodes.io\ndef get_geolocation(postcode):\n    response = requests.get(f\"http://api.postcodes.io/postcodes/{postcode}\")\n    if response.status_code == 200:\n        data = response.json()\n        return (data['result']['latitude'], data['result']['longitude'])\n    else:\n        return None\n\n# Function to check if a postcode is full (based on the pattern observed)\ndef is_full_postcode(postcode):\n    return len(postcode) &gt; 5 and postcode.isalnum() and not postcode.isalpha()\n\n# Initialize columns for geolocation data\nsurvey_with_postcodes['postcode_1_geo'] = None\nsurvey_with_postcodes['postcode_2_geo'] = None\nsurvey_with_postcodes['postcode_3_geo'] = None\n\n# Process only full postcodes and store geolocation data\ngeolocated_count = 0\nfor col in ['postcode_1', 'postcode_2', 'postcode_3']:\n    for index, row in survey_with_postcodes.iterrows():\n        if pd.notna(row[col]) and is_full_postcode(row[col]):\n            location = get_geolocation(row[col])\n            if location:\n                survey_with_postcodes.at[index, f'{col}_geo'] = location\n                geolocated_count += 1\n\n# Save the updated DataFrame as a pickle file\nsurvey_with_postcodes.to_pickle('data/survey_with_postcodes_geoapi.pkl')\n\n# Descriptive summaries\n#print(f\"Total postcodes geolocated: {geolocated_count}\")\n\n\n\n\nCode\nimport pandas as pd\nimport folium\nfrom folium.plugins import HeatMap\n\n# Load data from both surveys\nsurvey_with_postcodes_geojson = pd.read_pickle('data/survey_with_postcodes_geojson.pkl')\nsurvey_with_postcodes_geoapi = pd.read_pickle('data/survey_with_postcodes_geoapi.pkl')\n\n# Create a map object centered on a default UK location\ncombined_heatmap = folium.Map(location=[54.7, -3.4], zoom_start=6)\n\n# Heatmap Layer - Including all postcode centroids from the first survey\nheat_data = []\ngeojson_non_na_count = 0\nfor _, row in survey_with_postcodes_geojson.iterrows():\n    for col in ['geom_postcode_1', 'geom_postcode_2', 'geom_postcode_3']:\n        if pd.notna(row[col]):\n            heat_data.append([row[col].centroid.y, row[col].centroid.x])\n            geojson_non_na_count += 1\n\n# Add geolocation data from the second survey\ngeoapi_non_na_count = 0\nfor _, row in survey_with_postcodes_geoapi.iterrows():\n    for col in ['postcode_1_geo', 'postcode_2_geo', 'postcode_3_geo']:\n        location = row[col]\n        if location and isinstance(location, tuple) and len(location) == 2:\n            # Check if both elements of the tuple are numbers (not None)\n            if all(isinstance(coord, (int, float)) for coord in location):\n                heat_data.append(location)\n                geoapi_non_na_count += 1\n\n# Add HeatMap layer with combined data\nheatmap_layer = HeatMap(heat_data, name=\"Combined Heatmap\")\nheatmap_layer.add_to(combined_heatmap)\n\n# Save and display the combined heatmap\ncombined_heatmap.save('combined_heatmap.html')\n\n# Print the total number of non-NA geolocated coordinates\n#print(f\"Total non-NA geolocated coordinates in survey_with_postcodes_geojson: {geojson_non_na_count}\")\n#print(f\"Total non-NA geolocated coordinates in survey_with_postcodes_geoapi: {geoapi_non_na_count}\")\n#print(f\"Grand total of non-NA geolocated coordinates: {geojson_non_na_count + geoapi_non_na_count}\")\n\n# Display the map\ncombined_heatmap\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "projects/mapmind/mapmind_mapping.html#nation-influences-year-started-teaching",
    "href": "projects/mapmind/mapmind_mapping.html#nation-influences-year-started-teaching",
    "title": "MapMind (Part I): Mapping the Mindfulness Movement",
    "section": "Nation Influences Year Started Teaching",
    "text": "Nation Influences Year Started Teaching\nIn an analysis using Pandas, PrettyTable, and the SciPy ANOVA function (f_oneway), the dataset on mindfulness teaching across various nations was explored. The analysis focused on the year_started variable, representing the year in which mindfulness teaching commenced. A PrettyTable displayed aggregated data, including mean, median, minimum, maximum years, and counts, sorted by the median year_started in ascending order for each nation.\nANOVA, or Analysis of Variance, is a statistical technique used to compare the means of three or more independent groups to determine if there’s a statistically significant difference among them. In the given context, ANOVA is applied to compare the average year in which mindfulness teachers began teaching across various nations. The Statistic in the ANOVA table, the F-statistic, is a ratio of the variance between group means to the variance within the groups. A high F-statistic suggests a greater difference between the group means relative to the variation within the groups. In these results, the F-statistic is 15.651623486005224, indicating that the ratio of between-group variance to within-group variance is substantial.\nThe p-value in an ANOVA test helps determine the significance of the results. It’s the probability of observing the results if the null hypothesis (which states that there are no differences among group means) is true. A very small p-value, like these results (2.8012685079689403e-12), suggests that the null hypothesis can be rejected. This means there’s a statistically significant difference in the average year mindfulness teachers started teaching among different nations. The extremely low p-value, much smaller than the standard threshold of 0.05, indicates strong evidence against the null hypothesis, suggesting that the variation in the start year of mindfulness teaching among the nations is significant and not due to random chance.\nThe ANOVA test revealed significant differences in the starting years across nations, indicating variability in when mindfulness teaching was initiated in different regions. Key insights include Northern Ireland having the earliest median starting year, contrasted with Wales and Scotland having the latest. The ANOVA test, used for the numeric variable year_started, highlights significant differences in the start year of mindfulness teaching across nations.\nThese results imply both cultural and systemic differences in mindfulness teaching practices, with certain nations adopting seeing mindfulness teaching earlier or more extensively, and others showing historical trends in the adoption of mindfulness teaching.\n\n\nCode\nimport pandas as pd\nimport plotly.graph_objs as go\n\n# Load the survey dataset\nsurvey = pd.read_pickle('data/survey_tidy.pkl')\n\n# Drop NaN values from the 'year_started' column\nsurvey = survey.dropna(subset=['year_started'])\n\n# Convert 'year_started' to integer\nsurvey['year_started'] = survey['year_started'].astype(int)\n\n# Group the data by 'nations', calculate statistics, and sort by Median Year\ngrouped_data = survey.groupby('nations', observed=True)['year_started'].agg(['mean', 'median', 'min', 'max', 'count'])\nsorted_data = grouped_data.sort_values(by='median').reset_index()\n\n# Create a table with Plotly Express graph objects\ntable_trace = go.Table(\n    header=dict(values=[\"Nation\", \"Mean Year\", \"Median Year\", \"Min Year\", \"Max Year\", \"Count\"]),\n    cells=dict(values=[sorted_data['nations'], sorted_data['mean'], sorted_data['median'], \n                       sorted_data['min'], sorted_data['max'], sorted_data['count']],\n               format=[None, \".2f\", None, None, None, None])\n)\n\nlayout = dict(\n    title=\"Year Started Teaching Across Nations\",\n    autosize=False,\n    width=800,\n    height=400\n)\n\ntable_fig = go.Figure(data=[table_trace], layout=layout)\ntable_fig.show()\n\n\n\n                                                \n\n\n\n\nCode\nimport pandas as pd\nimport plotly.graph_objs as go\nfrom scipy.stats import f_oneway\n\n# Load the survey_tidy dataset\nsurvey_tidy = pd.read_pickle('data/survey_tidy.pkl')\n\n# Filter out groups with insufficient data\nvalid_groups = {nation: data for nation, data in \n                survey_tidy.groupby('nations', observed=True)['year_started']\n                if len(data.dropna()) &gt; 1}\n\n# Conduct ANOVA for 'year_started' with 'nations' with valid groups\nanova_nations_result = f_oneway(*(group.dropna() for group in valid_groups.values()))\n\n# Create a table with Plotly Express graph objects\ntable_trace = go.Table(\n    header=dict(values=[\"Test\", \"Statistic\", \"P-Value\"]),\n    cells=dict(values=[[\"Nations vs year_started\"], [anova_nations_result.statistic], [anova_nations_result.pvalue]],\n               format=[None, \".4f\", \".4f\"])\n)\n\nlayout = dict(\n    title=\"ANOVA Test on Nations vs Year Started Teaching\",\n    autosize=False,\n    width=600,\n    height=300\n)\n\ntable_fig = go.Figure(data=[table_trace], layout=layout)\ntable_fig.show()\n\n\n\n                                                \n\n\n\n\nCode\n# Calculate the median 'year_started' for each nation\nmedians = survey_tidy.groupby('nations')['year_started'].median().sort_values()\n\n# Boxplot to explore 'year_started' vs 'nations'\nplt.figure(figsize=(12, 6))\nsns.boxplot(x='nations', y='year_started', data=survey_tidy, order=medians.index)\nplt.title('Year Started Teaching Mindfulness vs Nations')\nplt.xlabel('Nations')\nplt.ylabel('Year Started Teaching')\nplt.xticks(rotation=45)  # Rotate the x-axis labels for better readability\nplt.show()"
  },
  {
    "objectID": "projects/mapmind/mapmind_mapping.html#overview-of-findings",
    "href": "projects/mapmind/mapmind_mapping.html#overview-of-findings",
    "title": "MapMind (Part I): Mapping the Mindfulness Movement",
    "section": "Overview of Findings",
    "text": "Overview of Findings\nThe analysis in this project utilized K-Means clustering to explore the urban concentrations of mindfulness teaching, demonstrating its effectiveness in handling large geospatial datasets. K-Means, known for its simplicity, efficiency, and interpretability, is an unsupervised learning algorithm well-suited for exploratory data analysis (EDA). This approach was pivotal in uncovering inherent patterns in the distribution of mindfulness teaching, especially in urban areas, without relying on pre-labeled data. The algorithm excelled in revealing natural groupings based on spatial proximity, providing valuable insights into the clustering of mindfulness practices and their geographical distribution. This analysis highlighted trends, regional differences, and the influence of national characteristics on mindfulness teaching, offering a nuanced understanding of how mindfulness is disseminated and practiced across different urban settings."
  },
  {
    "objectID": "projects/mapmind/mapmind_mapping.html#future-potentials",
    "href": "projects/mapmind/mapmind_mapping.html#future-potentials",
    "title": "MapMind (Part I): Mapping the Mindfulness Movement",
    "section": "Future Potentials",
    "text": "Future Potentials\nMapMind paves the way for further research and improved accessibility in mindfulness teaching. The project’s methodology and findings can inspire similar studies in different regions or pertaining to other wellness practices. By enhancing our understanding of mindfulness teaching locations and methods, the project contributes to making these teachings more accessible and inclusive, potentially leading to wider societal benefits, such as enhanced mental health and wellbeing.\nBy putting people at the heart of research on technology, we have revealed hidden patterns in the data. We used a nationwide online survey to discover the human stories behind the visualisations, and produced valuable insights which can inform how the world could change.\nOverall, MapMind is more than a project; it’s a pioneering effort towards a more mindful, informed society, illustrating the impactful role of data and technology in deepening our grasp and application of mind-body wellness practices."
  },
  {
    "objectID": "projects/mapmind/mapmind_technology.html",
    "href": "projects/mapmind/mapmind_technology.html",
    "title": "MapMind (Part III): Digital Divides: Mindfulness Teaching & Technology",
    "section": "",
    "text": "Code\n# Import libraries\nimport numpy as np\nimport pandas as pd\nimport itertools\nimport statsmodels.formula.api as smf\nimport statsmodels.api as sm\nfrom scipy.stats import chi2_contingency\nfrom prettytable import PrettyTable\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom imblearn.over_sampling import SMOTE"
  },
  {
    "objectID": "projects/mapmind/mapmind_technology.html#majority-start-to-teach-mindfulness-between-2012-2014",
    "href": "projects/mapmind/mapmind_technology.html#majority-start-to-teach-mindfulness-between-2012-2014",
    "title": "MapMind (Part III): Digital Divides: Mindfulness Teaching & Technology",
    "section": "3.1 Majority start to teach mindfulness between 2012-2014",
    "text": "3.1 Majority start to teach mindfulness between 2012-2014\nIn the analysis of the year_started variable from a mindfulness teaching survey, Python libraries pandas, prettytable, seaborn, and matplotlib.pyplot were employed. The survey data revealed that among 722 respondents, the average start year of teaching mindfulness was 2012, with a standard deviation of 6 years, ranging from 1974 to 2019. The median start year was 2014, indicating a more recent trend in mindfulness teaching.\nComplementing these statistics, a violin plot was generated to visualize the distribution of the start years. This plot not only confirmed the central tendency and spread captured by the numerical data but also provided a deeper insight into the density and distribution patterns of the years when respondents began their mindfulness teaching journey. The combined use of descriptive statistics and the violin plot offers a comprehensive understanding of the temporal trends in mindfulness teaching among the survey participants.\nOverall, our participants start to teach mindfulness between 1974 and 2019, with 50% starting to teach from 2014, and the mean average starting to teach in 2012. These years correspond with the development of popular technologies - such as computers, the internet, and mobile phones. But while there are a substantial number of participants who start teaching mindfulness in the past 10 years in particular, we should remember that correlation is not causation. The rise of mindfulness teaching might be correlated with the rise of technology, rather than caused by the rise of technology.\n\n\nCode\n# Load the survey dataframe\nsurvey = pd.read_pickle('data/tidied_survey.pkl')\n\n# Remove rows with NA from the 'year_started' column\nsurvey_clean = survey.dropna(subset=[\"year_started\"])\n\n# Generate descriptive statistics for 'year_started'\ndescriptive_stats = survey_clean['year_started'].describe()\n\n# Round the mean and convert all statistics to integers\ndescriptive_stats_rounded = descriptive_stats.round().astype(int)\n\n# Prepare data for the table\ncells_data = {\n    \"Statistic\": descriptive_stats_rounded.index,\n    \"Value\": descriptive_stats_rounded.values\n}\n\n# Create the table\nfig = go.Figure(data=[go.Table(\n    header=dict(values=[\"Statistic\", \"Value\"],\n                fill_color='lightgrey',\n                align='left',\n                font=dict(color='black', size=12)),\n    cells=dict(values=[cells_data[k] for k in cells_data.keys()],\n               fill_color='white',\n               align='left',\n               font=dict(color='black', size=11),\n               height=30)  # Smaller height for rows\n)])\n\nfig.update_layout(\n    title_text='Year Started Teaching Mindfulness',\n    title_x=0.5,\n    title_font=dict(size=14, family=\"Verdana\"),\n    paper_bgcolor='white',\n    plot_bgcolor='white',\n    margin=dict(l=20, r=20, t=50, b=20)  # Adjusted margins to center the table while keeping title\n)\n\n# Set the size of the table\nfig.update_layout(width=500, height=300)\n\nfig.show()\n\n\n\n                                                \n\n\n\n\nCode\n# Load the survey dataframe\nsurvey = pd.read_pickle('data/tidied_survey.pkl')\n\n# Remove rows with NA from the 'year_started' column\nsurvey_clean = survey.dropna(subset=[\"year_started\"])\n\n# Create a violin plot using seaborn for the 'year_started' variable\nplt.figure(figsize=(10, 6))\nsns.violinplot(data=survey_clean, x=\"year_started\", inner=\"quartile\")\n\n# Customize the plot\nplt.title('Distribution of Year Started Teaching')\nplt.xlabel('Year Started Teaching')\nplt.grid(True)\nsns.set_style(\"whitegrid\")\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "projects/mapmind/mapmind_technology.html#majority-use-technology-have-a-website-but-had-not-taught-online",
    "href": "projects/mapmind/mapmind_technology.html#majority-use-technology-have-a-website-but-had-not-taught-online",
    "title": "MapMind (Part III): Digital Divides: Mindfulness Teaching & Technology",
    "section": "3.2 Majority use technology, have a website, but had not taught online",
    "text": "3.2 Majority use technology, have a website, but had not taught online\nWe found some interesting contradictions in our data relating to how our participants engage with technology.\n\nThe majority of our participants use technologies when teaching mindfulness. These technologies include smartphone apps, books, compact discs, course notes, MP3/podcasts, posters/PowerPoint, physical props such as foot items or musical instruments (excluding chairs/cushions), websites, video clips, flipcharts.\nThe majority have a professional website for their mindfulness work.\nThe majority had never taught mindfulness online.\n\nThe following code analyses our participants’ use of technology, professional websites, and online teaching. Pandas is used for data manipulation and Plotly Express for generating the graph. In the results, a significant majority (91.48%, n=644) of participants use technology in their teaching. Regarding professional website usage, a majority (60.31%, n=392) have one, while 39.69% (n=258) do not.\n\n\nCode\nimport pandas as pd\nimport plotly.express as px\n\n# Load the survey dataframe\nsurvey = pd.read_pickle('data/tidied_survey.pkl')\n\n# Convert data to long format for faceting\nsurvey_long = survey.melt(id_vars=[], value_vars=['technology', 'website', 'online_teaching'], \n                          var_name='demographic', value_name='value')\n\n# Calculate frequency for each value within each demographic\nsurvey_freq = survey_long.groupby(['demographic', 'value'], observed=True).size().reset_index(name='freq')\n\n# Remove NA values\nsurvey_freq = survey_freq.dropna(subset=['value'])\n\n# Convert the 'value' column to a category\nsurvey_freq['value'] = survey_freq['value'].astype('category')\n\n# Arrange by demographic and frequency\nsurvey_freq = survey_freq.sort_values(by=['demographic', 'freq'], ascending=[True, True])\n\n# Calculate percentage\nsurvey_freq['percentage'] = survey_freq.groupby('demographic')['freq'].transform(lambda x: x / x.sum() * 100)\n\n# Plot with Plotly Express\nfig = px.bar(survey_freq, x='value', y='percentage', color='value', facet_col='demographic', \n             labels={'value': 'Value', 'percentage': 'Percentage'}, \n             category_orders={'demographic': ['technology', 'website', 'online_teaching']},\n             height=400, width=1000,\n             hover_data={'freq': ':.0f', 'percentage': ':.2f%'})\n\n# Update layout to match the aesthetics\nfig.update_layout(\n    title_text=\"Mindfulness Teachers' Use of Technologies\",\n    title_x=0.5,\n    title_font=dict(size=14, family=\"Verdana\"),\n    showlegend=False,\n    paper_bgcolor='white',\n    plot_bgcolor='white'\n)\n\n# Update axes labels\nfig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1]))\nfig.update_xaxes(showticklabels=True)\nfig.update_yaxes(title='Percentage')\n\nfig.show()\n\n\n\n                                                \n\n\nAs for online teaching, a larger proportion (74.30%, n=532) have not taught mindfulness online, while 25.70% (n=184) have. These statistics provide insights into the digital engagement of mindfulness teachers, highlighting a strong inclination towards using technology and websites, but less so for online teaching.\n\n\nCode\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n# Load the survey dataframe\nsurvey = pd.read_pickle('data/tidied_survey.pkl')\n\ndef plot_bar(data, var_name, title):\n    # Ensure the variable is categorical\n    data[var_name] = pd.Categorical(data[var_name])\n\n    # Filter out missing values\n    filtered_data = data.dropna(subset=[var_name])\n\n    # Count occurrences with observed=True\n    count_data = filtered_data.groupby(var_name, observed=True).size().reset_index(name='n')\n\n    # Sort by frequency in descending order\n    count_data = count_data.sort_values(by='n', ascending=False)\n\n    # Create a bar plot\n    fig = px.bar(count_data, x='n', y=var_name, orientation='h', \n                 color=var_name, title=title, \n                 labels={'n': 'Frequency'})\n    fig.update_layout(showlegend=False, template='plotly_white')\n\n    return fig, count_data\n\n# Generate plot and frequency data for online_n variable\np, freq_data = plot_bar(survey, 'online_n', 'Number of Students Taught Online')\n\n# Calculate percentages for the table\ntotal_count = freq_data['n'].sum()\nfreq_data['Percentage'] = (freq_data['n'] / total_count) * 100\n\n# Create a Plotly table\nfig_table = go.Figure(data=[go.Table(\n    header=dict(values=[\"Value\", \"Frequency\", \"Percentage\"],\n                fill_color='paleturquoise',\n                align='left'),\n    cells=dict(values=[freq_data['online_n'], freq_data['n'], freq_data['Percentage'].apply(lambda x: f\"{x:.2f}%\")],\n               fill_color='lavender',\n               align='left'))\n])\n\n# Add title to the table\nfig_table.update_layout(title_text=\"Number of Students Taught Online\", title_x=0.5)\n\n# Display the Plotly table\nfig_table.show()\n\n# Display the bar plot\np.show()"
  },
  {
    "objectID": "projects/mapmind/mapmind_technology.html#what-factors-predict-mindfulness-teaching",
    "href": "projects/mapmind/mapmind_technology.html#what-factors-predict-mindfulness-teaching",
    "title": "MapMind (Part III): Digital Divides: Mindfulness Teaching & Technology",
    "section": "3.3 What factors predict mindfulness teaching?",
    "text": "3.3 What factors predict mindfulness teaching?\nStatistical tests were conducted to find out the factors which significantly predict mindfulness teaching.\nChi-Squared tests were conducted to identify significant relations between pairs of variables. The significant results are visualised below using an interactive scatter plot.\nThe significant results are then displayed in a Plotly Express table sorted by Chi-Squared statistic, which indicates the strength of the significant relationship.\n\n3.3.1 Predictors\n\nAge (age)\nGender (gender)\nNations where mindfulness is taught (nations)\nEthnicity (ethnicity)\nSexuality (sexuality)\nDisability (disability)\nEmployment (employment_other_type)\nFormal Education (formal_education)\nManagement (management)\nSupervise Employees (supervise_emp)\nSocial Class (social_class)\nYear Started Teaching (can act as either predictor or outcome variable) (year_started)\n\n\n\n3.3.2 Outcomes\n\nTechnology (technology)\nWebsite (website)\nOnline Teaching (online_teaching)\nNumber of Students Taught Online (online_n)\n\n\n\n3.3.3 Significant Predictors and Outcomes\nWe conducted in-depth analyses of the predictor-and-outcome pairs which are significantly related. This report focuses on the factors which influence mindfulness teaching in relation to technology. The rest of the report summarises the in-depth analyes of the following significantly related factors.\nAge and use of a professional website Age and use of technology\nFormal education and use of technology\nGender and online teaching Gender and number of students taught online\nManagement role and online teaching Management role and number of students taught online Management role and use of a professional website\nNations where mindfulness is taught and number of students taught online Nations where mindfulness is taught and online teaching Nations where mindfulness is taught and use of a professional website\nYear started teaching and number of studens taught online Year started teaching and online teaching Year started teaching and use of a professional website\n\n\nCode\n# Load the survey dataframe\nsurvey_social_class_merged = pd.read_pickle('data/survey_social_class_merged.pkl')\n\n# Define independent and dependent variables\nindependent_vars = ['age', 'gender', 'nations', 'ethnicity', 'sexuality', 'disability', \n                    'employment_other_type', 'formal_education', 'management', 'supervise_emp', 'social_class']\ndependent_vars = ['technology', 'website', 'online_teaching', 'online_n']\nyear_started = ['year_started']  # can act as both IV and DV\n\n# Function to perform chi-squared tests and return results as a DataFrame\ndef perform_chi_squared_tests(data):\n    results = []\n\n    # Create all unique pairs of IVs and DVs, including year_started as both\n    for var1, var2 in itertools.product(independent_vars + year_started, dependent_vars + year_started):\n        if var1 != var2:\n            # Drop NaN values separately for the variables being tested\n            data_cleaned = data.dropna(subset=[var1, var2])\n\n            # Conduct chi-squared test\n            table = pd.crosstab(data_cleaned[var1], data_cleaned[var2])\n            chi2_stat, p_val, dof, _ = chi2_contingency(table)\n\n            # Check if the relationship is significant (using a threshold, e.g., 0.05)\n            if p_val &lt; 0.05:\n                # Store results in list\n                results.append([f\"{var1.capitalize()} vs {var2.capitalize()}\",\n                                chi2_stat, dof, p_val, len(data) - len(data_cleaned),\n                                f\"{var1}: {data_cleaned[var1].nunique()}, {var2}: {data_cleaned[var2].nunique()}\"])\n\n    # Convert results to DataFrame\n    results_df = pd.DataFrame(results, columns=[\"Test\", \"Chi-Squared Statistic\", \"Degrees of Freedom\", \"P-Value\", \"NaNs Dropped\", \"Unique Cases\"])\n\n    # Sort results by chi-squared statistic (descending)\n    results_df.sort_values(by=\"Chi-Squared Statistic\", ascending=False, inplace=True)\n\n    return results_df\n\n# Perform chi-squared tests\nsignificant_results_df = perform_chi_squared_tests(survey_social_class_merged)\n\n# Use Plotly Express to create an interactive scatter plot\nfig = px.scatter(significant_results_df, x=\"Test\", y=\"Chi-Squared Statistic\", \n                 size=\"Chi-Squared Statistic\", color=\"P-Value\", \n                 hover_data=[\"Degrees of Freedom\", \"NaNs Dropped\", \"Unique Cases\"],\n                 title=\"Chi-Squared Test Results: Tests vs Chi-Squared Statistic\",\n                 labels={\"Test\": \"Test\", \"Chi-Squared Statistic\": \"Chi-Squared Statistic\", \"P-Value\": \"P-Value\"},\n                 category_orders={\"Test\": significant_results_df[\"Test\"]})  # Order x-axis based on sorted Test names\nfig.show()\n\n\n\n                                                \n\n\n\n\nCode\nimport pandas as pd\nfrom scipy.stats import chi2_contingency\nimport itertools\nimport plotly.graph_objects as go\n\n# Load the survey dataframe\nsurvey_social_class_merged = pd.read_pickle('data/survey_social_class_merged.pkl')\n\n# Define independent and dependent variables\nindependent_vars = ['age', 'gender', 'nations', 'ethnicity', 'sexuality', 'disability', \n                    'employment_other_type', 'formal_education', 'management', 'supervise_emp', 'social_class']\ndependent_vars = ['technology', 'website', 'online_teaching', 'online_n']\nyear_started = ['year_started']  # can act as both IV and DV\n\n# Function to perform chi-squared tests and return Plotly table for significant results\ndef perform_chi_squared_tests(data):\n    significant_results = []  # List to hold the significant results\n\n    # Create all unique pairs of IVs and DVs, including year_started as both\n    for var1, var2 in itertools.product(independent_vars + year_started, dependent_vars + year_started):\n        if var1 != var2:\n            # Drop NaN values separately for the variables being tested\n            data_cleaned = data.dropna(subset=[var1, var2])\n\n            # Count unique cases for each variable\n            cases_var1 = data_cleaned[var1].nunique()\n            cases_var2 = data_cleaned[var2].nunique()\n\n            # Conduct chi-squared test\n            table = pd.crosstab(data_cleaned[var1], data_cleaned[var2])\n            chi2_stat, p_val, dof, _ = chi2_contingency(table)\n\n            # Check if the relationship is significant (using a threshold, e.g., 0.05)\n            if p_val &lt; 0.05:\n                # Append results to the list\n                result = [f\"{var1.capitalize()} vs {var2.capitalize()}\",\n                          round(chi2_stat, 2), dof, p_val, data[var1].isna().sum() + data[var2].isna().sum(),\n                          f\"{var1}: {cases_var1}, {var2}: {cases_var2}\"]\n                significant_results.append(result)\n\n    # Sort the results by Chi-Squared statistic in descending order\n    significant_results.sort(key=lambda x: x[1], reverse=True)\n\n    # Create a Plotly table\n    fig = go.Figure(data=[go.Table(\n        header=dict(values=[\"Test\", \"Chi-Squared Statistic\", \"Degrees of Freedom\", \"P-Value\", \"NaNs Dropped\", \"Unique Cases\"]),\n        cells=dict(values=list(zip(*significant_results)))\n    )])\n    fig.update_layout(title=\"Significant Results of Chi-Squared Tests (Sorted by Chi-Squared Statistic)\")\n    return fig\n\n# Perform chi-squared tests\nsignificant_results_fig = perform_chi_squared_tests(survey_social_class_merged)\n\n# Show the table\nsignificant_results_fig.show()\n\n\n\n                                                \n\n\n\n\nCode\n# Load the survey dataframe\nsurvey_social_class_merged = pd.read_pickle('data/survey_social_class_merged.pkl')\n\n# Define independent and dependent variables\nindependent_vars = ['age', 'gender', 'nations', 'ethnicity', 'sexuality', 'disability', \n                    'employment_other_type', 'formal_education', 'management', 'supervise_emp', 'social_class']\ndependent_vars = ['technology', 'website', 'online_teaching', 'online_n']\nyear_started = ['year_started']  # can act as both IV and DV\n\n# Function to perform chi-squared tests and return PrettyTables for significant results\ndef perform_chi_squared_tests(data):\n    significant_results = []  # List to hold the significant results\n\n    # Create all unique pairs of IVs and DVs, including year_started as both\n    for var1, var2 in itertools.product(independent_vars + year_started, dependent_vars + year_started):\n        if var1 != var2:\n            # Drop NaN values separately for the variables being tested\n            data_cleaned = data.dropna(subset=[var1, var2])\n\n            # Count unique cases for each variable\n            cases_var1 = data_cleaned[var1].nunique()\n            cases_var2 = data_cleaned[var2].nunique()\n\n            # Conduct chi-squared test\n            table = pd.crosstab(data_cleaned[var1], data_cleaned[var2])\n            chi2_stat, p_val, dof, _ = chi2_contingency(table)\n\n            # Check if the relationship is significant (using a threshold, e.g., 0.05)\n            if p_val &lt; 0.05:\n                # Append results to the list\n                result = [f\"{var1.capitalize()} vs {var2.capitalize()}\",\n                          round(chi2_stat, 2), dof, p_val, data[var1].isna().sum() + data[var2].isna().sum(),\n                          f\"{var1}: {cases_var1}, {var2}: {cases_var2}\"]\n                significant_results.append(result)\n\n    # Sort the results by Chi-Squared statistic in descending order\n    significant_results.sort(key=lambda x: x[1], reverse=True)\n\n    # Create PrettyTable\n    significant_results_pt = PrettyTable()\n    significant_results_pt.field_names = [\"Test\", \"Chi-Squared Statistic\", \"Degrees of Freedom\", \"P-Value\", \"NaNs Dropped\", \"Unique Cases\"]\n\n    # Add sorted results to PrettyTable\n    for result in significant_results:\n        significant_results_pt.add_row(result)\n\n    return significant_results_pt\n\n# Perform chi-squared tests\nsignificant_results_table = perform_chi_squared_tests(survey_social_class_merged)\n\n# Print the tables\nprint(\"Significant Results of Chi-Squared Tests (Sorted by Chi-Squared Statistic)\")\nprint(significant_results_table)\n\n\nSignificant Results of Chi-Squared Tests (Sorted by Chi-Squared Statistic)\n+----------------------------------+-----------------------+--------------------+------------------------+--------------+---------------------------------------+\n|               Test               | Chi-Squared Statistic | Degrees of Freedom |        P-Value         | NaNs Dropped |              Unique Cases             |\n+----------------------------------+-----------------------+--------------------+------------------------+--------------+---------------------------------------+\n|     Nations vs Year_started      |         357.92        |        124         | 1.4812594771090533e-24 |     102      |      nations: 5, year_started: 32     |\n|     Year_started vs Online_n     |         224.63        |        186         |  0.02787858124579619   |      98      |     year_started: 32, online_n: 7     |\n|      Gender vs Year_started      |         156.99        |         93         | 3.7834731846553706e-05 |     157      |      gender: 4, year_started: 32      |\n| Formal_education vs Year_started |         144.59        |         93         | 0.0004924966160509624  |     158      | formal_education: 4, year_started: 32 |\n|   Social_class vs Year_started   |         106.0         |         72         |  0.005634770537570735  |     384      |   social_class: 4, year_started: 25   |\n|       Nations vs Online_n        |         84.74         |         24         | 1.0490895829140457e-08 |     108      |        nations: 5, online_n: 7        |\n|    Disability vs Year_started    |         82.66         |         62         |  0.04090118508719291   |     157      |    disability: 3, year_started: 32    |\n|    Management vs Year_started    |         70.85         |         31         | 5.911878441903842e-05  |      69      |    management: 2, year_started: 32    |\n|    Nations vs Online_teaching    |         66.29         |         4          | 1.3754273150038289e-13 |     108      |     nations: 5, online_teaching: 2    |\n| Year_started vs Online_teaching  |         60.04         |         31         | 0.0013354744184983205  |      98      |  year_started: 32, online_teaching: 2 |\n|     Year_started vs Website      |         47.04         |         31         |  0.03245109949998662   |     164      |      year_started: 32, website: 2     |\n|        Gender vs Online_n        |         35.32         |         18         |   0.0086047412791464   |     163      |         gender: 4, online_n: 7        |\n|        Nations vs Website        |         29.04         |         4          |  7.67459815372819e-06  |     174      |         nations: 5, website: 2        |\n|      Management vs Online_n      |         22.71         |         6          | 0.0008988874890842292  |      75      |       management: 2, online_n: 7      |\n|  Management vs Online_teaching   |         19.95         |         1          | 7.944536694548721e-06  |      75      |   management: 2, online_teaching: 2   |\n|          Age vs Website          |         18.24         |         9          |  0.03249831224734725   |     229      |          age: 10, website: 2          |\n|    Supervise_emp vs Online_n     |          16.0         |         6          |  0.013742089030228081  |     393      |     supervise_emp: 2, online_n: 7     |\n|    Gender vs Online_teaching     |          14.2         |         3          |  0.002640469571142925  |     163      |     gender: 4, online_teaching: 2     |\n|  Formal_education vs Technology  |         12.65         |         3          |  0.005469060567803969  |     176      |   formal_education: 4, technology: 2  |\n| Supervise_emp vs Online_teaching |         11.99         |         1          | 0.0005354725303368053  |     393      |  supervise_emp: 2, online_teaching: 2 |\n|      Management vs Website       |          8.06         |         1          |  0.004522527714554017  |     141      |       management: 2, website: 2       |\n|     Supervise_emp vs Website     |          5.62         |         1          |  0.017784974068109444  |     459      |      supervise_emp: 2, website: 2     |\n+----------------------------------+-----------------------+--------------------+------------------------+--------------+---------------------------------------+"
  },
  {
    "objectID": "projects/mapmind/mapmind_technology.html#summary-of-logistic-regression-analysis",
    "href": "projects/mapmind/mapmind_technology.html#summary-of-logistic-regression-analysis",
    "title": "MapMind (Part III): Digital Divides: Mindfulness Teaching & Technology",
    "section": "4.1 Summary of Logistic Regression Analysis",
    "text": "4.1 Summary of Logistic Regression Analysis\n\n4.1.1 Overall Interpretation\n\nFormal Education as a Stronger Predictor: Formal education level is a more significant predictor of technology use in mindfulness teaching than age.\nModerate Accuracy: The model has an accuracy of approximately 61.67%, indicating moderate predictive power.\nBalanced Predictions: The model shows balanced precision, recall, and F1-scores for both classes (technology use and non-use).\n\nThe data was loaded and preprocessed, age and formal education were encoded, and SMOTE was used to balance the dataset. A logistic regression model was built and trained. The model coefficients were calculated to indicate the influence of age and formal education on use of technology. The coefficients show for age (0.0592) and formal education (0.7411) suggest formal education is a stronger influence than age on use of technology.\n\nFormal education level is a more significant predictor of technology use in mindfulness teaching than age.\n\nHowever, the ROC AUC - which assesses the model’s ability to distinguish between classes (in this case, age and formal education), was approximately 0.604, indicating limited discrimination ability between classes.\nThe confusion matrix and classification report provides detailed insights into model performance, reflecting a balance between precision and recall for predicting both technology use and non-use.\nOverall, this analysis suggests the need for further model refinement and consideration of additional variables to enhance predictive accuracy.\n\n\nCode\n# Load the survey dataframe\nsurvey_clean = pd.read_pickle('data/tidied_survey.pkl')\n\n# Convert the necessary columns to 'category' type\ncategory_columns = ['age', 'technology', 'formal_education']\nfor col in category_columns:\n    survey_clean[col] = survey_clean[col].astype('category')\n\n# Drop rows with NaN values in the relevant columns\nsurvey_clean = survey_clean.dropna(subset=category_columns).copy()\n\n# Convert 'technology' from Yes/No to 0/1\nsurvey_clean.loc[:, 'technology'] = survey_clean['technology'].map({'Yes': 1, 'No': 0})\n\n# Encoding 'age' and 'formal_education'\nage_mapping = {'25-29': 1, '30-34': 2, '35-39': 3, '40-44': 4, '45-49': 5,\n               '50-54': 6, '55-59': 7, '60-64': 8, '65+': 9, 'Prefer not to say': 10}\neducation_mapping = {'Non-degree': 1, 'Degree': 2, 'Higher degree': 3, 'Prefer not to say': 4}\nsurvey_clean.loc[:, 'age_encoded'] = survey_clean['age'].map(age_mapping)\nsurvey_clean.loc[:, 'formal_education_encoded'] = survey_clean['formal_education'].map(education_mapping)\n\n# Ensure no NaN values remain\nsurvey_clean = survey_clean.dropna(subset=['age_encoded', 'formal_education_encoded'])\n\n# Define predictor variables and outcome variable\nX = survey_clean[['age_encoded', 'formal_education_encoded']]\ny = survey_clean['technology']\n\n# Addressing Imbalance using SMOTE\nsm = SMOTE(random_state=42)\nX_res, y_res = sm.fit_resample(X, y)\n\n# Split dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.3, random_state=0)\n\n# Build logistic regression model\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\n\n# Predict test set results and calculate accuracy\ny_pred = logreg.predict(X_test)\n\n# Model Coefficients\nprint(\"\\nModel Coefficients:\")\nfor col, coef in zip(X.columns, logreg.coef_[0]):\n    print(f\"{col}: {coef}\")\n\n# Evaluation Metrics\naccuracy = logreg.score(X_test, y_test)\nroc_auc = roc_auc_score(y_test, logreg.predict_proba(X_test)[:, 1])\nconf_matrix = confusion_matrix(y_test, y_pred)\nclass_report = classification_report(y_test, y_pred, zero_division=0)\n\nprint('\\nAccuracy of logistic regression classifier on test set:', accuracy)\nprint('\\nROC AUC Score:', roc_auc)\nprint('\\nConfusion Matrix:\\n', conf_matrix)\nprint('\\nClassification Report:\\n', class_report)\n\n\n\nModel Coefficients:\nage_encoded: 0.05916298277924694\nformal_education_encoded: 0.7411458427773902\n\nAccuracy of logistic regression classifier on test set: 0.6166666666666667\n\nROC AUC Score: 0.6036770163285502\n\nConfusion Matrix:\n [[104  84]\n [ 54 118]]\n\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.66      0.55      0.60       188\n           1       0.58      0.69      0.63       172\n\n    accuracy                           0.62       360\n   macro avg       0.62      0.62      0.62       360\nweighted avg       0.62      0.62      0.62       360"
  },
  {
    "objectID": "projects/mapmind/mapmind_technology.html#results",
    "href": "projects/mapmind/mapmind_technology.html#results",
    "title": "MapMind (Part III): Digital Divides: Mindfulness Teaching & Technology",
    "section": "5.1 Results",
    "text": "5.1 Results\nThe model shows that having a management role is a significant positive predictor for using a professional website, while age and nations where mindfulness is taught show a negative correlation. However, the overall accuracy and ROC AUC score suggest that the model has moderate predictive power, and there is substantial room for improvement.\n\n5.1.1 Website Variable Distribution\n\nHaving a Website (1): 392\nNot Having a Website (0): 258\n\n\n\n5.1.2 Model Coefficients\nThe model coefficients suggest the following positive correlations:\n\nManagement role is positively correlated with having a professional website (0.6109)\nVery slight positive impact on the likelihood of having a website the later year started teaching (0.00041)\n\nThe model coefficients suggest the following negative correlations:\n\nNegative correlation between nations where mindfulness is taught and having a professional website (-0.1856)\nSlight decrease in likelihood of having a professional website with increasing age (-0.06271)\n\n\n\n5.1.3 Model Performance\n\nAccuracy: 60.51% on the test set.\nROC AUC Score: 0.5509, indicating moderate discriminative ability.\n\n\n\n5.1.4 Classification Report\n\nPrecision for not having a website (0): 46%\nRecall for not having a website (0): 17%\nF1-Score for not having a website (0): 25%\nPrecision for having a website (1): 63%\nRecall for having a website (1): 88%\nF1-Score for having a website (1): 73%\n\n\n\nCode\n# Load the survey dataframe\nsurvey_clean = pd.read_pickle('data/tidied_survey.pkl')\n\n# Drop NA values from variables of interest\nsurvey_clean = survey_clean.dropna(subset=['age', 'management', 'website', 'year_started', 'nations'])\n\n# Print initial data types\nprint(\"Initial Data Types:\\n\", survey_clean[['age', 'management', 'website', 'year_started', 'nations']].dtypes)\n\n# Convert 'management' and 'website' from Yes/No to 0/1\nsurvey_clean['management'] = survey_clean['management'].map({'Yes': 1, 'No': 0})\nsurvey_clean['website'] = survey_clean['website'].map({'Yes': 1, 'No': 0})\n\n# Convert 'year_started' to integer\nsurvey_clean['year_started'] = survey_clean['year_started'].astype(int)\n\n# Encoding 'age' using the provided mapping\nage_mapping = {'25-29': 1, '30-34': 2, '35-39': 3, '40-44': 4, '45-49': 5,\n               '50-54': 6, '55-59': 7, '60-64': 8, '65+': 9, 'Prefer not to say': 10}\nsurvey_clean['age'] = survey_clean['age'].map(age_mapping)\n\n# Encoding 'nations' as numeric\nprint(\"Unique levels in 'nations':\\n\", survey_clean['nations'].unique())\nlabel_encoder = LabelEncoder()\nsurvey_clean['nations'] = label_encoder.fit_transform(survey_clean['nations'])\n\n# Print updated data types\nprint(\"Updated Data Types:\\n\", survey_clean[['age', 'management', 'website', 'year_started', 'nations']].dtypes)\n\n# Select only the relevant columns for the model\nX = survey_clean[['age', 'management', 'year_started', 'nations']]\ny = survey_clean['website']\n\n# Check balance of the 'website' variable\nwebsite_counts = y.value_counts()\nprint(\"Website Variable Distribution:\\n\", website_counts)\n\n# Proceed without SMOTE as the dataset is balanced\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n\n# Build logistic regression model\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\n\n# Predict test set results and calculate accuracy\ny_pred = logreg.predict(X_test)\n\n# Model Coefficients\nprint(\"\\nModel Coefficients:\")\nfor col, coef in zip(X_train.columns, logreg.coef_[0]):\n    print(f\"{col}: {coef}\")\n\n# Evaluation Metrics\naccuracy = logreg.score(X_test, y_test)\nroc_auc = roc_auc_score(y_test, logreg.predict_proba(X_test)[:, 1])\nconf_matrix = confusion_matrix(y_test, y_pred)\nclass_report = classification_report(y_test, y_pred, zero_division=0)\n\nprint('\\nAccuracy of logistic regression classifier on test set:', accuracy)\nprint('\\nROC AUC Score:', roc_auc)\nprint('\\nConfusion Matrix:\\n', conf_matrix)\nprint('\\nClassification Report:\\n', class_report)\n\n\nInitial Data Types:\n age             category\nmanagement      category\nwebsite         category\nyear_started       Int64\nnations         category\ndtype: object\nUnique levels in 'nations':\n ['England', 'Scotland', 'Wales', 'Mixed', 'Northern Ireland']\nCategories (5, object): ['England', 'Mixed', 'Northern Ireland', 'Scotland', 'Wales']\nUpdated Data Types:\n age             category\nmanagement      category\nwebsite         category\nyear_started       int64\nnations            int64\ndtype: object\nWebsite Variable Distribution:\n website\n1    392\n0    258\nName: count, dtype: int64\n\nModel Coefficients:\nage: -0.06397820148488526\nmanagement: 0.6646041957468247\nyear_started: -0.014330463117446483\nnations: -0.30960480135527685\n\nAccuracy of logistic regression classifier on test set: 0.6256410256410256\n\nROC AUC Score: 0.5727222222222222\n\nConfusion Matrix:\n [[ 17  58]\n [ 15 105]]\n\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.53      0.23      0.32        75\n           1       0.64      0.88      0.74       120\n\n    accuracy                           0.63       195\n   macro avg       0.59      0.55      0.53       195\nweighted avg       0.60      0.63      0.58       195"
  },
  {
    "objectID": "projects/mapmind/mapmind_technology.html#nation-where-mindfulness-is-taught-influences-uses-of-professional-website",
    "href": "projects/mapmind/mapmind_technology.html#nation-where-mindfulness-is-taught-influences-uses-of-professional-website",
    "title": "MapMind (Part III): Digital Divides: Mindfulness Teaching & Technology",
    "section": "6.1 Nation where mindfulness is taught influences uses of professional website",
    "text": "6.1 Nation where mindfulness is taught influences uses of professional website\nWe tested for differences in use of a professional website by nation (country).\nWe found:\n\nWales and Scotland show a moderate increase in website usage compared to England, and these increases are statistically significant: This means that the observed higher website usage in Wales and Scotland is not just due to random chance, but likely reflects a real trend.\nA strong decrease in website usage in the “Mixed” group compared to England, and this decrease is highly significant: This suggests a robust trend of lesser website usage in this group relative to England.\nA decrease in website usage in Northern Ireland compared to England, but the strength of this decrease is “very low”, and it’s not statistically significant: we can’t be confident that this observed decrease isn’t just due to random chance.\n\nIn summary, we found that mindfulness teachers who teach in both Wales and Scotland are using professional websites more than those teaching in England, with those teaching in Wales leading slightly.\n\nThose teaching in Wales are 2.38 times more likely to use websites compared to those in England.\nThose teaching in Scotland are 1.78 times more likely to use websites than those in England.\nThe odds ratio for Northern Ireland is “nearly 0”, indicating that there’s almost no chance for teachers from Northern Ireland to use a website compared to England. Participants teaching in Northern Ireland are hardly using websites at all, when compared to those teaching in England.\nThe “Mixed” group also tends to use websites less than those teaching in England, with an odds ratio of 0.37.\n\nWe tested for differences in online teaching by nation (country).\nWe found:\n\nMindfulness teachers teaching in Scotland seem to be doing more online teaching compared to England, while teachers who teach in a “Mix” of nations do significantly less. The other nations don’t show significant differences from England in terms of online teaching."
  },
  {
    "objectID": "projects/mapmind/mapmind_technology.html#factors-predicting-online-teaching",
    "href": "projects/mapmind/mapmind_technology.html#factors-predicting-online-teaching",
    "title": "MapMind (Part III): Digital Divides: Mindfulness Teaching & Technology",
    "section": "6.2 Factors Predicting Online Teaching",
    "text": "6.2 Factors Predicting Online Teaching\nA logistic regression model was trained to predict whether mindfulness teachers engage in online teaching based on several features, including gender, years of teaching experience, whether they hold a management position, and their nationality.\nThe results show the following positive associations:\n\nHolding a management position is positively associated with online teaching (0.625, positive coefficient)\nBeing male is positively associated with online teaching (0.495, positive coefficient)\nHaving an “Other” gender is positively associated with online teaching (0.0341, positive coefficient)\nPreferring not to specify gender is positively associated with online teaching (0.0113, positive coefficient)\n\nThe results show the following negative associations:\n\nThe number of years a teacher has been teaching is negatively associated with online teaching (-0.000033, negative coefficient)\nThe nation where mindfulness is taught has a negative association with online teaching (-0.258, negative coefficient)\n\nThe logistic regression model achieved an accuracy of 67% on the test set, indicating that it can predict online teaching behavior to some extent. However, it’s important to note that there is room for improvement in terms of precision and recall, especially for class 1 (engaging in online teaching, 43%). Further analysis and feature engineering may help improve the model’s performance.\n\n6.2.1 Model Performance:\n\nAccuracy of the logistic regression classifier on the test set: 0.67 (67%)\nROC AUC Score: 0.628\nConfusion Matrix:\n\nTrue Positives: 30\nFalse Positives: 39\nTrue Negatives: 102\nFalse Negatives: 27\n\n\n\n\n6.2.2 Classification Report:\n\nPrecision for class 0 (not engaging in online teaching): 0.79\nRecall for class 0: 0.72\nF1-score for class 0: 0.76\nPrecision for class 1 (engaging in online teaching): 0.43\nRecall for class 1: 0.53\nF1-score for class 1: 0.48\n\n\n\nCode\n# Load the survey dataframe\nsurvey_clean = pd.read_pickle('data/tidied_survey.pkl')\n\n# Convert 'management' and 'online_teaching' from Yes/No to 0/1\nsurvey_clean['management'] = survey_clean['management'].map({'Yes': 1, 'No': 0})\nsurvey_clean['online_teaching'] = survey_clean['online_teaching'].map({'Yes': 1, 'No': 0})\n\n# Drop NA values only from the variables being tested\ncols_to_check = ['gender', 'management', 'online_teaching', 'year_started', 'nations']\nsurvey_clean = survey_clean.dropna(subset=cols_to_check)\n\n# One-hot encoding for 'gender'\ngender_encoder = OneHotEncoder(drop='first', sparse_output=False)\ngender_encoded = gender_encoder.fit_transform(survey_clean[['gender']])\ngender_encoded_df = pd.DataFrame(gender_encoded, columns=gender_encoder.get_feature_names_out(['gender']))\n\n# Join the encoded dataframe with the original dataframe\nsurvey_clean = survey_clean.reset_index(drop=True)  # Resetting index to ensure proper row alignment\nsurvey_clean = pd.concat([survey_clean, gender_encoded_df], axis=1)\n\n# Encoding 'nations' as numeric\nlabel_encoder = LabelEncoder()\nsurvey_clean['nations'] = label_encoder.fit_transform(survey_clean['nations'])\n\n# Convert 'year_started' to integer\nsurvey_clean['year_started'] = survey_clean['year_started'].astype(int)\n\n# Select only the relevant columns for the model\nfeature_cols = ['management', 'year_started', 'nations'] + list(gender_encoded_df.columns)\nX = survey_clean[feature_cols]\ny = survey_clean['online_teaching']\n\n# Splitting the dataset into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n\n# Applying SMOTE to the training set\n# SMOTE - Synthetic Minority Over-sampling Technique\n# https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html\nsmote = SMOTE(random_state=0)\nX_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n\n# Drop rows with NaN values from X_train_smote\nX_train_smote = X_train_smote.dropna()\ny_train_smote = y_train_smote.loc[X_train_smote.index]  # Update y_train_smote accordingly\n\n# Build logistic regression model\nlogreg = LogisticRegression()\nlogreg.fit(X_train_smote, y_train_smote)\n\n# Predict test set results and calculate accuracy\ny_pred = logreg.predict(X_test)\n\n# Model Coefficients\nprint(\"\\nModel Coefficients:\")\nfor col, coef in zip(X_train_smote.columns, logreg.coef_[0]):\n    print(f\"{col}: {coef}\")\n\n# Evaluation Metrics\naccuracy = logreg.score(X_test, y_test)\nroc_auc = roc_auc_score(y_test, logreg.predict_proba(X_test)[:, 1])\nconf_matrix = confusion_matrix(y_test, y_pred)\nclass_report = classification_report(y_test, y_pred, zero_division=0)\n\nprint('\\nAccuracy of logistic regression classifier on test set:', accuracy)\nprint('\\nROC AUC Score:', roc_auc)\nprint('\\nConfusion Matrix:\\n', conf_matrix)\nprint('\\nClassification Report:\\n', class_report)\n\n\n\nModel Coefficients:\nmanagement: 0.6481850676166716\nyear_started: -9.213443896792867e-05\nnations: -0.3503226262337142\ngender_Male: 0.27240590910783763\ngender_Other, please specify: 0.5861393717995113\ngender_Prefer not to say: -0.27421669668555293\n\nAccuracy of logistic regression classifier on test set: 0.6363636363636364\n\nROC AUC Score: 0.5477168097548837\n\nConfusion Matrix:\n [[107  34]\n [ 38  19]]\n\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.74      0.76      0.75       141\n           1       0.36      0.33      0.35        57\n\n    accuracy                           0.64       198\n   macro avg       0.55      0.55      0.55       198\nweighted avg       0.63      0.64      0.63       198\n\n\n\n\n\nCode\n# Load the survey dataframe\nsurvey_clean = pd.read_pickle('data/tidied_survey.pkl')\n\n# Convert 'management' and 'online_teaching' from Yes/No to 0/1\nsurvey_clean['management'] = survey_clean['management'].map({'Yes': 1, 'No': 0})\nsurvey_clean['online_teaching'] = survey_clean['online_teaching'].map({'Yes': 1, 'No': 0})\n\n# Drop NA values only from the variables being tested\ncols_to_check = ['gender', 'management', 'online_teaching', 'year_started', 'nations']\nsurvey_clean = survey_clean.dropna(subset=cols_to_check)\n\n# One-hot encoding for 'gender'\ngender_encoder = OneHotEncoder(drop='first', sparse_output=False)\ngender_encoded = gender_encoder.fit_transform(survey_clean[['gender']])\ngender_encoded_df = pd.DataFrame(gender_encoded, columns=gender_encoder.get_feature_names_out(['gender']))\n\n# Join the encoded dataframe with the original dataframe\nsurvey_clean = survey_clean.reset_index(drop=True)  # Resetting index to ensure proper row alignment\nsurvey_clean = pd.concat([survey_clean, gender_encoded_df], axis=1)\n\n# Encoding 'nations' as numeric\nlabel_encoder = LabelEncoder()\nsurvey_clean['nations'] = label_encoder.fit_transform(survey_clean['nations'])\n\n# Convert 'year_started' to integer\nsurvey_clean['year_started'] = survey_clean['year_started'].astype(int)\n\n# Select only the relevant columns for the model\nfeature_cols = ['management', 'year_started', 'nations'] + list(gender_encoded_df.columns)\nX = survey_clean[feature_cols]\ny = survey_clean['online_teaching']\n\n# Splitting the dataset into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n\n# Handling NaN values using imputation\nimputer = SimpleImputer(strategy='mean')  # 'median' or 'most_frequent' is also possible\nX_train_imputed = imputer.fit_transform(X_train)\nX_test_imputed = imputer.transform(X_test)\n\n# Applying SMOTE to the imputed training set\nsmote = SMOTE(random_state=0)\nX_train_smote, y_train_smote = smote.fit_resample(X_train_imputed, y_train)\n\n# Build logistic regression model\nlogreg = LogisticRegression()\nlogreg.fit(X_train_smote, y_train_smote)\n\n# Predict test set results and calculate accuracy\ny_pred = logreg.predict(X_test_imputed)\n\n# Model Coefficients\nprint(\"\\nModel Coefficients:\")\nfor col, coef in zip(X_train.columns, logreg.coef_[0]):\n    print(f\"{col}: {coef}\")\n\n# Evaluation Metrics\naccuracy = logreg.score(X_test_imputed, y_test)\nroc_auc = roc_auc_score(y_test, logreg.predict_proba(X_test_imputed)[:, 1])\nconf_matrix = confusion_matrix(y_test, y_pred)\nclass_report = classification_report(y_test, y_pred, zero_division=0)\n\nprint('\\nAccuracy of logistic regression classifier on test set:', accuracy)\nprint('\\nROC AUC Score:', roc_auc)\nprint('\\nConfusion Matrix:\\n', conf_matrix)\nprint('\\nClassification Report:\\n', class_report)\n\n\n\nModel Coefficients:\nmanagement: 0.9471648623810215\nyear_started: -0.000249900349181266\nnations: -0.2560050081223515\ngender_Male: 0.33838255865305117\ngender_Other, please specify: 0.714905757478076\ngender_Prefer not to say: -0.06276762576369525\n\nAccuracy of logistic regression classifier on test set: 0.6717171717171717\n\nROC AUC Score: 0.6483762597984322\n\nConfusion Matrix:\n [[101  40]\n [ 25  32]]\n\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.80      0.72      0.76       141\n           1       0.44      0.56      0.50        57\n\n    accuracy                           0.67       198\n   macro avg       0.62      0.64      0.63       198\nweighted avg       0.70      0.67      0.68       198"
  },
  {
    "objectID": "testimonials.html",
    "href": "testimonials.html",
    "title": "Testimonials",
    "section": "",
    "text": "Dr. Meg-John Barker, writer, mentor and associate at Centre for Transforming Sexuality and Gender, University of Brighton\n\n“I consider Stephen to be an exceptional researcher who would be an asset to any organisation. I have known Stephen for over a decade as a friend and colleague. I consider their work to be some of the most important and innovative in the field, and I frequently draw upon it in my own writing. We have also collaborated together on a number of projects. We have conducted and published research together, as well as co-organising several conferences and other events. Most recently, I was a stakeholder/participant on their major funded project: ‘Mapping Mindfulness’. I can therefore speak to Stephen’s abilities, professionalism, communication skills, and qualities as a researcher and colleague. The ‘Mapping Mindfulness’ project employed an innovative participatory co-design, which meant that stakeholder/participants were engaged with in various ways throughout the research process. I certainly found that this approach enabled me to feel invested in the project, with the potential to engage in ways that ensured that the outcomes of the research would be helpful in relation to my own work. In all of their research, Stephen demonstrates clear, enthusiastic and insightful engagement with their stakeholders and participants, and a consistent commitment to ethical principles.”\n\n\n\nDuncan Moss, Clinical Psychologist & Researcher\n\n“I am a Clinical Psychologist and Researcher with over 30 years experience and have known Stephen for over 10 years. In that time we have collaborated (and I have participated) on a number of projects and I have come to know their abilities very well. Stephen is an extremely capable Researcher with a mastery of a wide range of research skills. In my experience, they are able to work with both data and people very capably. Stephen has a particular ability at synthesising wide ranging data - quantitative and qualitative - and putting these into a clear and coherent context. Their writing skills are extremely advanced in my opinion. I’ve also witnessed Stephen working closely with colleagues and participants, for example creatively organising, hosting and facilitating events with a wide range of people involved. Stephen’s calm, mindful and friendly demeanour and quiet leadership is always evident. I have no hesitation in recommending them as a fantastic asset to any organisation.”"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Skills",
    "section": "",
    "text": "📊 Excel\n🧮 Numpy\n📚 Pandas\n🔍 NVIVO\n📐 SPSS\n📖 Text Mining\n🧐 Thematic Analysis\n📏 Tidyverse (dplyr)"
  },
  {
    "objectID": "about.html#data-analysis",
    "href": "about.html#data-analysis",
    "title": "Skills",
    "section": "",
    "text": "📊 Excel\n🧮 Numpy\n📚 Pandas\n🔍 NVIVO\n📐 SPSS\n📖 Text Mining\n🧐 Thematic Analysis\n📏 Tidyverse (dplyr)"
  },
  {
    "objectID": "about.html#data-engineering",
    "href": "about.html#data-engineering",
    "title": "Skills",
    "section": "Data Engineering",
    "text": "Data Engineering\n\n🖥️ Bash\n🐋 Docker\n🌐 Git & GitHub\n🐧 Linux\n⚙️ NGINX\n🧪 Pytest\n💻 Shell Scripting"
  },
  {
    "objectID": "about.html#data-visualisation",
    "href": "about.html#data-visualisation",
    "title": "Skills",
    "section": "Data Visualisation",
    "text": "Data Visualisation\n\n📉 D3.js\n🗺️ Folium\n📊 Ggplot2\n🌍 Leaflet\n📈 Matplotlib\n📊 Plotly\n📈 Seaborn"
  },
  {
    "objectID": "about.html#databases-programming",
    "href": "about.html#databases-programming",
    "title": "Skills",
    "section": "Databases & Programming",
    "text": "Databases & Programming\n\n🐍 Python\n💻 R\n💾 SQL"
  },
  {
    "objectID": "about.html#dashboards-reporting",
    "href": "about.html#dashboards-reporting",
    "title": "Skills",
    "section": "Dashboards & Reporting",
    "text": "Dashboards & Reporting\n\n📄 LaTeX\n📊 Markdown\n📈 Quarto\n📊 Shiny\n📄 Sphynx\n📈 Streamlit"
  },
  {
    "objectID": "about.html#machine-learning",
    "href": "about.html#machine-learning",
    "title": "Skills",
    "section": "Machine Learning",
    "text": "Machine Learning\n\n🤖 Keras\n📜 NLTK\n🤖 Pytorch\n🧠 Scikit-Learn\n🧠 SpaCy\n🤖 Tensorflow"
  },
  {
    "objectID": "about.html#people-skills",
    "href": "about.html#people-skills",
    "title": "Skills",
    "section": "People Skills",
    "text": "People Skills\n\n🗣️ Communication\n🤝 Collaboration\n🌍 Cultural Awareness\n💡 Generating Insightful Impacts\n🌐 Global Experience\n📈 Leadership\n🧠 Lifelong Learning\n🤹 Marketing\n🧑‍🏫 Mentoring\n🧘‍♂️ Patience\n🎤 Presentations\n🤝 Project Management\n🧑‍🔬 Psychology\n🧑‍💼 Recruitment\n👥 Stakeholder Engagement\n🛠️ Teamwork"
  },
  {
    "objectID": "about.html#research",
    "href": "about.html#research",
    "title": "Skills",
    "section": "Research",
    "text": "Research\n\n🔬 Experiments\n🗣️ Interviews\n🧑‍🤝‍🧑 Focus Groups\n📊 Qualtrics\n📉 Survey Monkey\n🌐 Web Surveys"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Portfolio",
    "section": "",
    "text": "Welcome to our portfolio! 🤗\nSocial Data Science combines the tools of social science and data science to build solutions to complex social problems.\n\nWe decode the matrix of human relations with technology: by linking computation with interpretation, we tell the human stories behind the data.\nWe build machine learning solutions to create caring futures: a data revolution that is equitable, fair, and sustainable. Our solutions are infused with care, ethics, privacy. We are sensitive to cultural, geographical, historical circumstances, social contexts and differences that make a difference.\nWe use cutting-edge free and open source technologies to put people at the heart of the data. We inform evidence-based decision-making and actionable ‘outsights’ to make the world a better place.\n\nIn short, we care, code, connect.\nExplore our projects to find out more!\nThis portfolio was made with ❤️ using Python, Quarto and Shiny."
  },
  {
    "objectID": "projects/mapmind/mapmind_demographics.html",
    "href": "projects/mapmind/mapmind_demographics.html",
    "title": "MapMind (Part II): Who Are Mindfulness Teachers?",
    "section": "",
    "text": "The project studied the people at the forefront of the mindfulness movement"
  },
  {
    "objectID": "projects/mapmind/mapmind_demographics.html#majority-female-middle-aged",
    "href": "projects/mapmind/mapmind_demographics.html#majority-female-middle-aged",
    "title": "MapMind (Part II): Who Are Mindfulness Teachers?",
    "section": "3.1 Majority Female & Middle-Aged",
    "text": "3.1 Majority Female & Middle-Aged\nWe asked our participants to report their gender and age.\nWe found mindfulness teachers in the U.K. tend to be female and middle-aged.\n\n\nCode\nimport pandas as pd\nimport plotly.graph_objects as go\n\n# Load the modified DataFrame\nsurvey = pd.read_pickle('data/tidied_survey.pkl')\n\n# Assuming 'survey.gender' contains the gender data\ngender_data = survey['gender'].value_counts().reset_index()\ngender_data.columns = ['Gender', 'Count']\n\n# Creating a table with Plotly Graph Objects\nfig = go.Figure(data=[go.Table(\n    header=dict(values=list(gender_data.columns),\n                fill_color='paleturquoise',\n                align='left'),\n    cells=dict(values=[gender_data.Gender, gender_data.Count],\n               fill_color='lavender',\n               align='left'))\n])\n\nfig.update_layout(title='Gender of Mindfulness Teachers')\nfig.show()\n\n# Function to create a bar chart remains the same\ndef create_bar_chart(data, var_name, flip_axes=False):\n    # Filter out NA values\n    filtered_data = data.dropna(subset=[var_name])\n\n    # Create a bar chart using seaborn\n    plt.figure(figsize=(10, 6))\n    if not flip_axes:\n        sns.countplot(x=var_name, data=filtered_data, palette=\"Set3\", hue=var_name, legend=False)\n        plt.xticks(rotation=45)  # Rotate x-axis labels if needed\n    else:\n        sns.countplot(y=var_name, data=filtered_data, palette=\"Set3\", hue=var_name, legend=False)\n\n    plt.title(f\"Bar chart of {var_name}\")\n    plt.ylabel('Frequency' if not flip_axes else var_name)\n    plt.xlabel(var_name if not flip_axes else 'Frequency')\n    plt.show()\n\n# Example usage of the function for 'age'\ncreate_bar_chart(survey, 'age')"
  },
  {
    "objectID": "projects/mapmind/mapmind_demographics.html#majority-white-heterosexual-non-disabled",
    "href": "projects/mapmind/mapmind_demographics.html#majority-white-heterosexual-non-disabled",
    "title": "MapMind (Part II): Who Are Mindfulness Teachers?",
    "section": "3.2 Majority White, Heterosexual, & Non-Disabled",
    "text": "3.2 Majority White, Heterosexual, & Non-Disabled\nWe asked our participants to self-report their ethnicity, sexuality, and whether they considered themselves to have a disability.\nWe found they tended to self-report being white, heterosexual or straight, and non-disabled.\n\n\nCode\nimport pandas as pd\nimport plotly.graph_objects as go\nimport plotly.express as px\n\n# Load the modified DataFrame\nsurvey = pd.read_pickle('data/tidied_survey.pkl')\n\n# Convert data to long format for faceting\nsurvey_long = survey.melt(id_vars=['ResponseId'], value_vars=['ethnicity', 'sexuality', 'disability'], var_name='demographic', value_name='value')\n\n# Calculate frequency for each value within each demographic\nsurvey_freq = survey_long.groupby(['demographic', 'value']).size().reset_index(name='freq')\n\n# Remove NA values\nsurvey_freq = survey_freq.dropna(subset=['value'])\n\n# Rename \"Non-white\" to \"People of colour\" in ethnicity demographic\nsurvey_freq.loc[(survey_freq['demographic'] == 'ethnicity') & (survey_freq['value'] == 'Non-white'), 'value'] = 'People of colour'\n\n# Sort the frequencies in descending order\nsurvey_freq.sort_values(by=['demographic', 'freq'], ascending=[True, False], inplace=True)\n\n# Define the order of categories to be displayed\ncategories = ['ethnicity', 'sexuality', 'disability']\ntitles = ['Ethnicity of Mindfulness Teachers', 'Sexuality of Mindfulness Teachers', 'Disability Status of Mindfulness Teachers']\n\n# Creating tables and plotting for each category in the defined order\nfor category, title in zip(categories, titles):\n    # Filter data for the current category\n    cat_data = survey_freq[survey_freq['demographic'] == category]\n\n    # Creating a table with Plotly Graph Objects for the current category\n    fig_table = go.Figure(data=[go.Table(\n        header=dict(values=[category.capitalize(), 'Frequency'],\n                    fill_color='paleturquoise',\n                    align='left'),\n        cells=dict(values=[cat_data['value'], cat_data['freq']],\n                   fill_color='lavender',\n                   align='left'))\n    ])\n    fig_table.update_layout(title=title)\n    fig_table.show()\n\n    # Creating a bar plot with Plotly Express for the current category\n    fig_plot = px.bar(cat_data, x='freq', y='value', orientation='h', color='value', labels={'value': category.capitalize(), 'freq': 'Frequency'})\n    fig_plot.update_layout(title=f'Distribution of {category.capitalize()}')\n    fig_plot.show()"
  },
  {
    "objectID": "projects/mapmind/mapmind_demographics.html#majority-highly-educated",
    "href": "projects/mapmind/mapmind_demographics.html#majority-highly-educated",
    "title": "MapMind (Part II): Who Are Mindfulness Teachers?",
    "section": "3.3 Majority Highly Educated",
    "text": "3.3 Majority Highly Educated\nWe asked our participants to report their highest level of formal education.\nWe found the majority of our sample self-reported as highly educated to higher degree level.\n\n\nCode\nimport pandas as pd\nimport plotly.graph_objects as go\n\n# Load the modified DataFrame\nsurvey = pd.read_pickle('data/tidied_survey.pkl')\n\n# Calculate frequencies in descending order\neducation_counts = survey['formal_education'].value_counts().sort_values(ascending=False)\n\n# Calculate percentages\ntotal_responses = survey['formal_education'].count()\neducation_percentages = (education_counts / total_responses) * 100\n\n# Convert to DataFrame for Plotly\neducation_df = pd.DataFrame({\n    'Formal Education': education_counts.index,\n    'Frequency': education_counts.values,\n    'Percentage': education_percentages.values\n})\n\n# Create table using Plotly Graph Objects\nfig = go.Figure(data=[go.Table(\n    header=dict(values=list(education_df.columns),\n                fill_color='paleturquoise',\n                align='left'),\n    cells=dict(values=[education_df[k].round(2) if k == 'Percentage' else education_df[k] for k in education_df.columns], # Round percentages to 2 decimal places\n               fill_color='lavender',\n               align='left'))\n])\n\nfig.update_layout(title='Formal Education of Mindfulness Teachers')\nfig.show()\n\n# Create a countplot with bars in descending order of counts\nplt.figure(figsize=(10, 6))\nsns.set_style(\"whitegrid\")\nsns.countplot(data=survey, y='formal_education', hue='formal_education', palette='viridis', order=education_counts.index, legend=False)\nplt.xlabel('Count')\nplt.ylabel('Formal Education')\nplt.title('Education Levels')\nplt.show()"
  },
  {
    "objectID": "projects/mapmind/mapmind_demographics.html#majority-work-in-high-status-occupations",
    "href": "projects/mapmind/mapmind_demographics.html#majority-work-in-high-status-occupations",
    "title": "MapMind (Part II): Who Are Mindfulness Teachers?",
    "section": "3.4 Majority Work in High Status Occupations",
    "text": "3.4 Majority Work in High Status Occupations\nWe asked participants to choose the type of their non-mindfulness employment from the following list:\n\nModern professional occupations (teacher, nurse, physiotherapist, social worker, welfare officer, artist, musician, police officer, software designer)\nTraditional professional occupations (accountant, solicitor, medical practitioner, scientist, civil/mechanical engineer)\nSenior managers or administrators (planning, organising and co-ordinating work, finance manager, chief executive)\nClerical and intermediate occupations (secretary, personal assistant, clerical worker, office clerk, call centre agent, nursing auxiliary, nursery nurse)\nMiddle or junior managers (office manager, retail manager, bank manager, restaurant manager, warehouse manager, publican)\nSemi-routine manual and service occupations (postal worker, machine operative, security guard, caretaker, farm worker, catering assistant, receptionist, sales assistant)\nTechnical and craft occupations (motor mechanic, fitter, inspector, plumber, printer, tool maker, electrician, gardener, train driver)\nRoutine manual and service occupations (HGV driver, van driver, cleaner, porter, packer, sewing machinist, messenger, labourer, waiter/waitress, bar staff)\n\nWe found they tended to report working in high status employment types in their non-mindfulness work, with the majority working in modern professional occupations.\nThe analysis of the survey data reveals the following distribution of employment types among mindfulness teachers:\n\nThe most common category is Modern professional occupations, with a frequency of 307, indicating a significant representation in this group.\nThis is followed by Traditional professional occupations and Senior managers or administrators, with frequencies of 48 and 45, respectively.\nLess common categories include Clerical and intermediate occupations (14), Middle or junior managers (8), and both Semi-routine manual and service occupations and Technical and craft occupations with a frequency of 3 each. - The least common category is Routine manual and service occupations, noted only twice.\n\nThese results provide insights into the professional backgrounds of mindfulness teachers.\nThe following code loads the survey dataset, specifically focusing on the employment_other_type. It checks whether this variable is categorical and if it’s ordinal, then prints its categories. The code cleans the data by removing rows with NaN (‘Not a Number’) values and extracts the first part of the labels for conciseness. A visualization of the frequency of each employment type is generated, annotated with counts for clarity. The code maps these frequencies back to their original, longer labels, providing a comprehensive view of the employment types among mindfulness teachers.\n\n\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load the modified DataFrame\nsurvey = pd.read_pickle('data/tidied_survey.pkl')\n\n# Check if 'employment_other_type' is a categorical variable and if it is ordered\nis_categorical = isinstance(survey['employment_other_type'].dtype, pd.CategoricalDtype)\nis_ordered = survey['employment_other_type'].cat.ordered if is_categorical else False\n\n# Remove rows where 'employment_other_type' is NaN\nsurvey_clean = survey.dropna(subset=['employment_other_type']).copy()\n\n# Extract the first part of the labels before the brackets\nshortened_label_mapping = {label: label.split(' (')[0] for label in survey['employment_other_type'].cat.categories}\nsurvey_clean['employment_other_type_short'] = survey_clean['employment_other_type'].map(shortened_label_mapping)\n\n# Plot the frequencies of employment types with shortened labels\nplt.figure(figsize=(10, 8))\nemployment_order_short = survey_clean['employment_other_type_short'].value_counts().index\nax = sns.countplot(y='employment_other_type_short', data=survey_clean, order=employment_order_short)\nax.set_title('Frequency of Employment Types')\nax.set_xlabel('Frequency')\nax.set_ylabel('Employment Type')\n\n# Annotate the count on the bars\nfor p in ax.patches:\n    ax.annotate(f'{int(p.get_width())}', (p.get_width(), p.get_y() + p.get_height() / 2), ha='left', va='center')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nWe studied the prevalent employment backgrounds among mindfulness teachers and their correlation with formal education levels, indicating a significant representation from professional and managerial fields. This shows that participants’ highest formal education is most commonly higher degree and their most common employment type is modern professional occupations.\nThe following code explores the relationship between employment types and formal education of mindfulness teachers. A PrettyTable and a bar plot display the count of formal education across various employment types, ordered by their frequency in the dataset.\n\n\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom prettytable import PrettyTable\n\nimport pandas as pd\nimport plotly.graph_objects as go\n\n# Load the modified DataFrame\nsurvey = pd.read_pickle('data/tidied_survey.pkl')\n\n# Ensure 'employment_other_type' is treated as a categorical variable\nsurvey['employment_other_type'] = pd.Categorical(\n    survey['employment_other_type'],\n    categories=survey['employment_other_type'].cat.categories,\n    ordered=True\n)\n\n# Map employment types to numeric values (1-8) and create shortened labels\nemployment_mapping = {category: i for i, category in enumerate(survey['employment_other_type'].cat.categories, 1)}\nreverse_mapping = {v: k for k, v in employment_mapping.items()}\nshortened_label_mapping = {category: category.split(' (')[0] for category in survey['employment_other_type'].cat.categories}\nsurvey['employment_type_numeric'] = survey['employment_other_type'].map(employment_mapping)\nsurvey['employment_other_type_short'] = survey['employment_other_type'].map(shortened_label_mapping)\n\n# Create a frequency table with numeric and shortened employment type labels\nfrequency_counts = survey['employment_type_numeric'].value_counts().reset_index()\nfrequency_counts.columns = ['Employment Type Numeric', 'Frequency']\nfrequency_table = frequency_counts.copy()\nfrequency_table['Employment Type'] = frequency_table['Employment Type Numeric'].map(lambda x: shortened_label_mapping[reverse_mapping[x]])\n\n# Create a Plotly table\nfig = go.Figure(data=[go.Table(\n    header=dict(values=list(frequency_table.columns),\n                fill_color='paleturquoise',\n                align='left'),\n    cells=dict(values=[frequency_table[k].tolist() for k in frequency_table.columns],\n               fill_color='lavender',\n               align='left'))\n])\n\n# Update the layout\nfig.update_layout(\n    title='Employment Types'\n)\n\n# Show the figure\nfig.show()\n\n# Determine the order of bars based on frequency count\nnumeric_order = [employment_mapping[cat] for cat in survey['employment_other_type'].value_counts().index]\n\n# Create a plot showing the relationship between employment type and count of formal education\nplt.figure(figsize=(12, 6))\nsns.countplot(data=survey, x='employment_type_numeric', hue='formal_education', palette='viridis', order=numeric_order)\nplt.xlabel('Employment Type (1-8)')\nplt.ylabel('Count of Formal Education')\nplt.title('Formal Education across Employment Types')\nplt.xticks(ticks=range(len(numeric_order)), labels=[f'{i}' for i in numeric_order], rotation=45)\nplt.legend(title='Formal Education')\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/mapmind/mapmind_demographics.html#majority-middle-class-or-white-collar-professionals",
    "href": "projects/mapmind/mapmind_demographics.html#majority-middle-class-or-white-collar-professionals",
    "title": "MapMind (Part II): Who Are Mindfulness Teachers?",
    "section": "3.5 Majority Middle-Class or White-Collar Professionals",
    "text": "3.5 Majority Middle-Class or White-Collar Professionals\nOur data distribution suggests a diversity in the educational and professional backgrounds of mindfulness teachers, with a significant representation in middle and upper social classes. Our analysis of the survey data reveals the majority of teachers belong to the middle-white-collar_emp category (241 individuals), indicating a prevalent background in middle-class, white-collar professions. Upper-elite_emp is the next largest group (126 individuals), followed by working-blue-collar_emp (45 individuals), and upper-elite_plus (18 individuals).\nTo produce these results, we created a scoring system to classify the social class of mindfulness teachers, based on a combination of formal education, employment type, and roles in supervision or management. Teachers are categorized into Non-degree, Degree, and Higher degree for education, and their employment types are similarly classified. Additional points are awarded for supervisory and management roles, leading to four social class categories: working-blue-collar_emp, middle-white-collar_emp, upper-elite_emp, and ‘upper-elite_plus’.\nThe function calculate_social_class_score computes the social class score for mindfulness teachers based on their education (ed_class), employment type (emp_class), and roles in supervision and management. It uses a score_map where education and employment types are assigned scores: working-blue-collar and its employment counterpart are assigned 1 point, middle-white-collar and its employment equivalent get 2 points, and upper-elite categories receive 3 points.\nThe total base score for an individual is the sum of the points from their education and employment types. Additional bonus points are added based on their roles: 1 point if they have a supervisory role (supervise equals “Yes”) and 2 points for a management role (management equals “Yes”). The final score is a combination of the base score and any bonus points, reflecting their overall social class standing.\nThe following code analyzes the survey dataset and provides outsights into the distribution of social classes among survey respondents. The data is processed to classify individuals into different social classes based on their formal education, employment type, and work roles.\nThe following code processes the formal_education and employment_other_type columns to categorize them into different social classes. These categories are then used to calculate a social class score for each entry. The code also filters out irrelevant data (entries with Prefer not to say or missing employment types). After calculating the social class scores, the data is further classified into broader social class categories. The distribution of these classes is presented using a PrettyTable and a count plot. The table shows the frequency of each social class category, while the count plot visualizes the distribution of these categories in the dataset. This analysis and visualization help in understanding the composition of the dataset in terms of different social classes derived from education and employment types.\nWe discuss the potential limitations of our social class scoring system in the Conclusion.\n\n\nCode\nimport pandas as pd\n\n# Load the original DataFrame\nsurvey = pd.read_pickle('data/tidied_survey.pkl')\n\n# Create a new ordered categorical variable for 'formal_education'\neducation_order = [\"Non-degree\", \"Degree\", \"Higher degree\"]\nsurvey['formal_education_ordered'] = pd.Categorical(survey['formal_education'], categories=education_order, ordered=True)\n\n# Create a new variable based on 'formal_education_ordered'\ndef classify_education(edu):\n    if edu == \"Higher degree\":\n        return \"upper-elite\"\n    elif edu == \"Degree\":\n        return \"middle-white-collar\"\n    elif edu == \"Non-degree\":\n        return \"working-blue-collar\"\n    else:\n        return \"unclassified\"\n\nsurvey['social_class_ed'] = survey['formal_education_ordered'].apply(classify_education)\nsurvey['social_class_ed'] = pd.Categorical(survey['social_class_ed'], categories=[\"unclassified\", \"working-blue-collar\", \"middle-white-collar\", \"upper-elite\"], ordered=True)\n\n# Create a new variable 'employment_other_type_filtered' that filters out certain entries\nsurvey['employment_other_type_filtered'] = survey['employment_other_type']\nsurvey = survey[survey['employment_other_type_filtered'].notna() & (survey['employment_other_type_filtered'] != \"Prefer not to say\")]\n\n# Apply transformation to 'employment_other_type_filtered'\ndef classify_employment(emp_type):\n    # Replace with actual condition\n    if \"some condition or keyword for upper-elite_emp\" in emp_type:\n        return \"upper-elite_emp\"\n    elif \"some condition or keyword for middle-white-collar_emp\" in emp_type:\n        return \"middle-white-collar_emp\"\n    elif \"some condition or keyword for working-blue-collar_emp\" in emp_type:\n        return \"working-blue-collar_emp\"\n    else:\n        return \"unclassified\"\n\nsurvey['social_class_emp'] = survey['employment_other_type_filtered'].apply(classify_employment)\nsurvey['social_class_emp'] = pd.Categorical(survey['social_class_emp'], categories=[\"unclassified\", \"working-blue-collar_emp\", \"middle-white-collar_emp\", \"upper-elite_emp\"], ordered=True)\n\n# Calculate social class scores and create new variable\ndef calculate_social_class_score(ed_class, emp_class, supervise, management):\n    score_map = {'working-blue-collar': 1, 'middle-white-collar': 2, 'upper-elite': 3,\n                 'working-blue-collar_emp': 1, 'middle-white-collar_emp': 2, 'upper-elite_emp': 3}\n    base_score = score_map.get(ed_class, 0) + score_map.get(emp_class, 0)\n    bonus_points = 0\n    if supervise == \"Yes\":\n        bonus_points += 1\n    if management == \"Yes\":\n        bonus_points += 2\n    return base_score + bonus_points\n\nsurvey['social_scores'] = survey.apply(lambda row: calculate_social_class_score(\n    row['social_class_ed'], row['social_class_emp'], row.get('supervise_emp', 'No'), row.get('management', 'No')), axis=1)\n\n# Classify social class based on scores and create new variable\nscore_labels = [\"working-blue-collar_emp\", \"middle-white-collar_emp\", \"upper-elite_emp\", \"upper-elite_plus\"]\nsurvey['social_class'] = pd.cut(survey['social_scores'], bins=[-float('inf'), 2, 4, 6, float('inf')], labels=score_labels, right=False)\nsurvey['social_class'] = pd.Categorical(survey['social_class'], categories=score_labels)\n\n# Continue with further analysis or save the DataFrame\nsurvey.to_pickle('data/survey_social_class.pkl')\n\n\n\n\nCode\nimport pandas as pd\n\n# Load the survey dataframe\nsurvey_clean = pd.read_pickle('data/tidied_survey.pkl')\n\n# Load the modified DataFrame\nsurvey_social_class = pd.read_pickle('data/survey_social_class.pkl')\n\n# Check the number of rows and columns in survey_clean before the merge\n#print(\"Before Merge - survey_clean shape:\", survey_clean.shape)\n\n# Merge the dataframes based on 'ResponseId' using a left join\nsurvey_social_class_merged = survey_clean.merge(survey_social_class[['ResponseId', 'social_class']], on='ResponseId', how='left')\n\n# Check the number of rows and columns in survey_social_class_merged after the merge\n#print(\"After Merge - survey_social_class_merged shape:\", survey_social_class_merged.shape)\n\n# Now survey_social_class_merged contains the 'social_class' variable from survey_social_class\n\n# Continue with further analysis or save the DataFrame\nsurvey_social_class_merged.to_pickle('data/survey_social_class_merged.pkl')\n\n\n\n\nCode\n# Load the survey dataframe\nsurvey_social_class = pd.read_pickle('data/survey_social_class.pkl')\n\n# Load the survey dataframe\nsurvey_social_class_merged = pd.read_pickle('data/survey_social_class_merged.pkl')\n\n# Sample the same row numbers from the 'social_class' variable in both dataframes\nrow_numbers_to_sample = [1, 3, 5, 7]  # Replace with the row numbers you want to sample\n\n# Check if the row numbers exist in both dataframes before sampling\ncommon_row_numbers = set(row_numbers_to_sample) & set(survey_social_class.index) & set(survey_social_class_merged.index)\n\n# Create a new list of row numbers that exist in both dataframes\ncommon_row_numbers = list(common_row_numbers)\n\n# Sample the 'social_class' variable for the common row numbers\nsampled_social_class_survey_social_class = survey_social_class.loc[common_row_numbers, 'social_class']\nsampled_social_class_survey_social_class_merged = survey_social_class_merged.loc[common_row_numbers, 'social_class']\n\n# Print the descriptive summaries of the sampled 'social_class' variable in both dataframes\n#print(\"Descriptive Summary of 'social_class' in survey_social_class:\")\n#print(sampled_social_class_survey_social_class.describe())\n\n#print(\"\\nDescriptive Summary of 'social_class' in survey_social_class_merged:\")\n#print(sampled_social_class_survey_social_class_merged.describe())\n\n\n\n\nCode\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n# Load the modified DataFrame\nsurvey = pd.read_pickle('data/survey_social_class_merged.pkl')\n\n# Calculate the frequency and percentage of each social class\nvalue_counts = survey['social_class'].value_counts()\ntotal = value_counts.sum()\npercentages = (value_counts / total) * 100\n\n# Create a DataFrame for the table\ntable_df = pd.DataFrame({\n    \"Social Class\": value_counts.index,\n    \"Frequency\": value_counts.values,\n    \"Percentage\": percentages.values\n})\n\n# Create a Plotly table\nfig = go.Figure(data=[go.Table(\n    header=dict(values=list(table_df.columns),\n                fill_color='paleturquoise',\n                align='left'),\n    cells=dict(values=[table_df[k].tolist() for k in table_df.columns],\n               fill_color='lavender',\n               align='left'))\n])\n\n# Update the layout\nfig.update_layout(\n    title='Social Class of Mindfulness Teachers'\n)\n\n# Show the figure\nfig.show()\n\n# Prepare the DataFrame for Plotly Express\nsocial_class_counts = survey['social_class'].value_counts().reset_index()\nsocial_class_counts.columns = ['Social Class', 'Frequency']\n\n# Plot the distribution of 'social_class' using Plotly Express\nfig = px.bar(social_class_counts, x='Social Class', y='Frequency',\n             title=\"Distribution of Social Classes Based on Total Score\")\nfig.update_xaxes(title_text='Social Class')\nfig.update_yaxes(title_text='Number of Respondents')\nfig.show()\n\n# Optionally, print a sample of social class scores\n#print(\"Sample of social class scores:\\n\", survey['social_scores'].sample(5))"
  },
  {
    "objectID": "projects/mapmind/mapmind_demographics.html#overview",
    "href": "projects/mapmind/mapmind_demographics.html#overview",
    "title": "MapMind (Part II): Who Are Mindfulness Teachers?",
    "section": "4.1 Overview",
    "text": "4.1 Overview\nBy putting people at the heart of research on technology, we have revealed hidden patterns in the data, the human stories behind the visualisations, and produced valuable outsights which can inform how the world could change.\nOn the one hand, the majority of our participants are a somewhat privileged group: white, heterosexual or straight, non-disabled, highly educated, working in high status occupations, with high social class status.\nOn the other hand, they are predominantly female and middle-aged."
  },
  {
    "objectID": "projects/mapmind/mapmind_demographics.html#limitations-future-potential",
    "href": "projects/mapmind/mapmind_demographics.html#limitations-future-potential",
    "title": "MapMind (Part II): Who Are Mindfulness Teachers?",
    "section": "4.2 Limitations & Future Potential",
    "text": "4.2 Limitations & Future Potential\nOverall, we need to be careful when interpreting the findings of our survey, and keep the following limitations in mind when evaluating our findings:\n\nWhile likely representing the majority of mindfulness teachers who were active during 2017-2021, our study mostly took place before the COVID-19 pandemic, which might have led to significant changes in the mindfulness field.\nWe used a convenience sample, with voluntary participation. This design is potentially subject to a self-selection bias, where those who responded might have different characteristics to those who did not reply. Our sample might not be representative of the wider U.K. population.\nWe could have situated our survey sample in relation to the U.K. population as a whole by integrating census data. This could be especially interesting for the geographical mapping presented in MapMind (Part I).\nWe could pay more in-depth attention the experiences of participants in the minority of our sample: people of colour, of diverse sexualities, with working class backgrounds. We could explore these participants’ experiences in greater depth.\nThe social class scoring system is based on understandings of the social status and the social hierarchies of employment, education, supervision, and management from sociology. Obviously, this data needs to be treated with some caution, because unlike the other demographic variables, we have classified the social class of our participants, based on their self-reported status. Nevertheless, it is striking the degree to which a majority of our participants have high level formal education, combined with high status occupations.\n\nThe study’s limitations, primarily its reliance on self-reported data and the need for broader demographic representation, pave the way for future research to build upon these findings and explore other influential factors in mindfulness teaching.\nBy putting people at the heart of the data revolution, we can reveal previously hidden inter-sectional patterns, thus promoting decision-making for fairer, more equal and sustainable futures.\nWe can use the tools of free and open science - especially Python - to make the findings of quantitative research, data analysis, and data science broadly accessible to a wide audience."
  },
  {
    "objectID": "projects/server/server.html",
    "href": "projects/server/server.html",
    "title": "Building a Data Science Server on Raspberry Pi",
    "section": "",
    "text": "graph TD;\n    A[Raspberry Pi 5] --&gt;|Hosts| B[Ubuntu Server];\n    B --&gt; C[SSH for Remote Access];\n    B --&gt;|Web Server| D[NGINX];\n    D --&gt; E[UFW Firewall];\n    D --&gt;|SSL Encryption| F[SSL Certificates];\n    B --&gt;|Publishing & Presentation| G[Quarto];\n    G --&gt;|Content Editing| H[Visual Studio Code];\n    G --&gt;|Version Control| I[Git with GitHub];\n    H --&gt;|Remote Development| J[VS Code Remote Development Extension];\n\n    style A fill:#f9f,stroke:#333,stroke-width:2px\n    style B fill:#fcf,stroke:#333,stroke-width:2px\n    style C fill:#cff,stroke:#333,stroke-width:2px\n    style D fill:#fcf,stroke:#333,stroke-width:2px\n    style E fill:#cff,stroke:#333,stroke-width:2px\n    style F fill:#fcf,stroke:#333,stroke-width:2px\n    style G fill:#cff,stroke:#333,stroke-width:2px\n    style H fill:#fcf,stroke:#333,stroke-width:2px\n    style I fill:#cff,stroke:#333,stroke-width:2px\n    style J fill:#fcf,stroke:#333,stroke-width:2px"
  },
  {
    "objectID": "projects/server/server.html#installing-ubuntu-server-on-raspberry-pi",
    "href": "projects/server/server.html#installing-ubuntu-server-on-raspberry-pi",
    "title": "Building a Data Science Server on Raspberry Pi",
    "section": "Installing Ubuntu Server on Raspberry Pi",
    "text": "Installing Ubuntu Server on Raspberry Pi\nHere’s a short guide with the necessary steps to install Ubuntu Server on a Raspberry Pi in a headless setup using a desktop or laptop computer on the same network as the Raspberry Pi, with SSH:\n\nFlash Ubuntu Server on Raspberry Pi:\n\nDownload the Raspberry Pi Imager from the Raspberry Pi website on your desktop or laptop computer.\nInsert the microSD card into your computer.\nUse Raspberry Pi Imager to flash Ubuntu Server onto the microSD card.\n\nInitial Raspberry Pi Setup:\n\nInsert the flashed microSD card into your Raspberry Pi.\nConnect the Raspberry Pi to your network via Ethernet.\nPower up your Raspberry Pi without connecting it to a monitor or keyboard.\n\nSSH into Raspberry Pi:\n\nDetermine the Raspberry Pi’s IP address from your router’s DHCP lease table.\nSSH into your Raspberry Pi from your ThinkPad using the IP address.\n\n\n# Replace 'raspberry_pi_ip' with the actual IP address of your Raspberry Pi\nssh ubuntu@raspberry_pi_ip"
  },
  {
    "objectID": "projects/server/server.html#update-and-upgrade-ubuntu-server",
    "href": "projects/server/server.html#update-and-upgrade-ubuntu-server",
    "title": "Building a Data Science Server on Raspberry Pi",
    "section": "Update and Upgrade Ubuntu Server",
    "text": "Update and Upgrade Ubuntu Server\nOnce logged in, update and upgrade the system.\nsudo apt update\nsudo apt upgrade"
  },
  {
    "objectID": "projects/server/server.html#checking-raspberry-pi-health",
    "href": "projects/server/server.html#checking-raspberry-pi-health",
    "title": "Building a Data Science Server on Raspberry Pi",
    "section": "Checking Raspberry Pi Health",
    "text": "Checking Raspberry Pi Health\nVerify the Raspberry Pi is running and its hardware is functioning correctly:\n# Check CPU load\ntop\n\n# Check memory usage\nfree -h\n\n# Check disk space usage\ndf -h\n\n# Check the Raspberry Pi model and Ubuntu version:\ncat /proc/device-tree/model\nlsb_release -a\n\nVerify Network Configuration\n# Display network interfaces and IP addresses\nip addr show\n\n# Test internet connectivity\nping -c 4 google.com\n\n\nCheck Network and IP Addresses\nIdentify the local and public IP addresses of the Raspberry Pi. You will need these later! Make a note of them.\nip addr show\ncurl ifconfig.me/ip\nNow we’ve setup a Raspberry Pi running Ubuntu Server, which you can access and control using SSH from your desktop or laptop computer.\n\n\nBuy Domain and Setup SSL Certificate\nI bought the domain name carecodeconnect.io and setup a subdomain portfolio.carecodeconnect.io with Namecheap and configured an SSL certificate, which ensures the security of the website. This process involves purchasing a domain, obtaining an SSL certificate, and concatenating the CRT files for SSL setup.\n\n\n1. Visit Namecheap\n\nGo to Namecheap and search for your desired domain name.\nChoose the domain you want and proceed to purchase it.\nComplete the checkout process by creating an account and making the payment.\n\n\n\n2. Purchase SSL Certificate\n\nAfter purchasing your domain, you can buy an SSL certificate from Namecheap.\nLook for options like PositiveSSL under the SSL certificate section.\nComplete the purchase and go through the process of domain validation.\n\n\n\n3. Concatenating the CRT Files\nAfter receiving your SSL certificate files, concatenate them for proper setup on your server.\n\nDownload the SSL certificate files (usually a .zip file) to your server.\nExtract the files:\n\nunzip your_site.zip\n\nConcatenate the domain certificate file and the CA bundle file into a single file:\n\ncat your_site.crt your_site.ca-bundle &gt; combined_your_site.crt\nThis creates a single combined CRT file that can be used in your web server configuration later."
  },
  {
    "objectID": "projects/server/server.html#setting-up-web-server",
    "href": "projects/server/server.html#setting-up-web-server",
    "title": "Building a Data Science Server on Raspberry Pi",
    "section": "Setting Up Web Server",
    "text": "Setting Up Web Server\nWhen choosing the best web server solution, I chose between Apache and NGINX, which are both popular web servers. Apache, known for its robustness and flexibility, has a wide range of modules that allow for extensive configuration and customization. For a Raspberry Pi 5, which has limited resources compared to full-scale servers, NGINX is often the more suitable choice. Its low memory footprint and ability to handle numerous simultaneous connections without significant resource consumption align well with the hardware constraints of the Raspberry Pi.\n\n1. Setting Up NGINX and UFW Firewall\nInstall and start NGINX, and then set up UFW to allow necessary traffic:\nsudo apt install nginx\nsudo systemctl start nginx\nsudo systemctl status nginx\n\nsudo ufw allow ssh\nsudo ufw enable\nsudo ufw allow http\nsudo ufw allow https\nsudo ufw allow 'Nginx Full'\nsudo ufw status verbose\n\n\n2. SSL Certificate Configuration\nGenerate an SSL certificate for the website:\nopenssl req -new -newkey rsa:2048 -nodes -keyout your_site.key -out your_site.csr\nsudo mv your_site.key /etc/ssl/private/\nsudo chmod 600 /etc/ssl/private/your_site.key\nsudo mkdir /etc/ssl/csr/\nsudo mv your_site.csr /etc/ssl/csr/\n\n\n3. SSL Certificate Configuration\nAfter generating the CSR, you’ll need to submit it to a Certificate Authority to obtain an SSL certificate. Once you have your SSL certificate (your_site.crt), install it along with the key:\nsudo mv your_site.crt /etc/ssl/\nsudo chmod 600 /etc/ssl/private/your_site.key\n\n\n4. NGINX Configuration\nConfigure NGINX to serve your Quarto website and enable SSL:\nsudo nano /etc/nginx/sites-available/portfolio\nThe NGINX configuration file should look something like this:\nserver {\n    listen 80;\n    listen [::]:80;\n    listen 443 ssl;\n    listen [::]:443 ssl;\n    ssl_certificate /etc/ssl/your_site.crt;\n    ssl_certificate_key /etc/ssl/private/your_site.key;\n    # ... additional SSL configurations ...\n    server_name your_site;\n    root /var/www/portfolio/_site;\n    index index.html index.htm;\n    location / {\n        try_files $uri $uri/ =404;\n    }\n}\n\n\n5. Test NGINX\n# Test NGINX configuration for syntax errors\nsudo nginx -t\n\n\n6. DNS Configuration\nEnsure your domain’s DNS settings have A and AAAA records pointing to your Raspberry Pi’s public IP addresses:\nA Record for local_ip\nAAAA Record for public_ip"
  },
  {
    "objectID": "projects/server/server.html#setting-up-website-development-and-publishing-tools",
    "href": "projects/server/server.html#setting-up-website-development-and-publishing-tools",
    "title": "Building a Data Science Server on Raspberry Pi",
    "section": "Setting Up Website Development and Publishing Tools",
    "text": "Setting Up Website Development and Publishing Tools\nQuarto is a scientific and technical publishing system that allows you to create dynamic documents, presentations, and websites. It supports multiple programming languages, including Python, R, and Julia, enabling the integration of code and its output (like plots and tables) directly into the content.\nI decided to use Quarto as my web publishing system because it is a highly suitable and powerful tool for data science publishing, especially when compared to traditional static site generators like Hugo. One of the key strengths of Quarto lies in its native support for Jupyter notebooks and Python, which are cornerstone technologies in the data science and machine learning communities. This integration allows data scientists to directly embed code, results, and visualizations from Python or Jupyter notebooks into their web content, ensuring that the published material is not only informative but also interactive and dynamically up-to-date.\nQuarto is particularly useful for creating rich, interactive documents where the narrative is supported by data and visualizations. It also excels in generating static content like reports, articles, presentations, and blogs where reproducibility and presentation of data are key.\nAdditionally, Quarto’s Markdown-based syntax simplifies the process of content creation, making it more accessible to users who may not have extensive web development experience. This ease of use, combined with its powerful features for data visualization and analysis, positions Quarto as a superior choice for building a data science or machine learning website. It not only facilitates effective communication of complex data-driven insights but also enhances the overall user engagement through interactive content, which is a significant advantage over Hugo for data science applications.\n\nSetting up Quarto\n\n\n1. Installing Quarto\nInstall Quarto and create a new project for the portfolio website:\nsudo wget https://github.com/quarto-dev/quarto-cli/releases/download/v1.3.450/quarto-1.3.450-linux-arm64.deb\nsudo dpkg -i quarto-1.3.450-linux-arm64.deb\nquarto --version\ncd /var/www\nsudo quarto create project website portfolio\ncd /var/www/portfolio\nquarto render\nTo set up a basic Quarto portfolio website using the Cerulean Bootswatch theme, used for this portfolio, follow these steps. At the time of writing, Bootswatch offers 26 different themes. This guide assumes you will use the Cerulean theme and have Quarto installed and a basic understanding of its usage.\n\n\n2. Create a New Quarto Project\nCreate a new Quarto project in your desired directory:\n# Navigate to your desired directory\ncd path/to/your/directory\n\n# Create a new Quarto project\nquarto create project portfolio\n\n\n3. Configuring NGINX for Quarto Website\nUpdate NGINX configuration to serve the Quarto website:\nsudo nano /etc/nginx/sites-available/portfolio\n# Add the server block configuration here\nsudo ln -s /etc/nginx/sites-available/portfolio /etc/nginx/sites-enabled/\nsudo nginx -t\nsudo systemctl restart nginx\n\n\n4. Set Up the Quarto Configuration\nIn the _quarto.yml file, set up your website configuration. I’m using the Cerulean bootswatch theme.\nproject:\n  type: website\n\nwebsite:\n  title: \"Portfolio\"\n  navbar:\n    right:\n      - href: index.qmd\n        text: Home\n      - href: about.qmd\n        text: About\n      - href: projects.qmd\n        text: Projects\n\nformat:\n  html:\n    theme: cerulean\n    css: css/styles.css\n    toc: false\n\n\n5. Create Content Files\nCreate your main content files, such as index.qmd, about.qmd, and projects.qmd. Here’s an example for index.qmd:\n---\ntitle: \"Portfolio\"\nformat: \n    html:\n        code-fold: true\n---\n\nYour text here.\nAnd for projects.qmd:\n---\ntitle: \"Projects\"\npage-layout: full\ntitle-block-banner: true\n---\n\n# My Projects\n\nYour text here.\n\n## [Project 1 Title](projects/project1.qmd)\nBrief description of Project 1. \n\n\n6. Add Project Details\nFor each project, create a .qmd file in the projects directory. For example, project1.qmd:\n---\ntitle: \"Project 1 Title\"\n---\n\n# Project 1\n\n[Details about Project 1]\nRepeat this for each project.\n\n\n7. Render Your Website\nFinally, render your website:\nquarto render\nThis will generate your website with the Cerulean Bootswatch theme. You can then view it locally or deploy it to a web server."
  },
  {
    "objectID": "projects/server/server.html#version-control-with-git-and-github",
    "href": "projects/server/server.html#version-control-with-git-and-github",
    "title": "Building a Data Science Server on Raspberry Pi",
    "section": "Version Control with Git and GitHub",
    "text": "Version Control with Git and GitHub\nInitialize a Git repository and push the website code to GitHub:\ngit init\ngit add .\ngit commit -m \"Initial commit\"\ngit remote add origin https://github.com/your_username/portfolio.git\ngit push -u origin main\ngit status"
  },
  {
    "objectID": "projects/server/server.html#automating-website-publishing",
    "href": "projects/server/server.html#automating-website-publishing",
    "title": "Building a Data Science Server on Raspberry Pi",
    "section": "Automating Website Publishing",
    "text": "Automating Website Publishing\nI’ve automated the process of publishing my website. This involves updating with git/GitHub, rendering with Quarto, and restarting the NGINX server. This is how I did it:\n\n1. Create a Bash Script\n\nUse a text editor such as nano to create a Bash script (e.g., sudo nano publish_website.sh) using the following guide.\nModify the paths in the script according to your project and server setup.\nReplace user_name with your user name and repo_name with your GitHub repository name.\n\nThe following script:\n\nNavigates to your Quarto project directory.\nIt adds, commits, and pushes changes to your Git repository.\nQuarto builds the website.\nThe built website is synced to the NGINX directory.\nNGINX is reloaded to reflect the changes.\n\n#!/bin/bash\n\n# Navigate to the Quarto project directory\ncd /home/user_name/projects/portfolio\n\n# Add all new and changed files to Git\necho \"Adding changes to Git...\"\ngit add .\n\n# Commit the changes with a standard message. You can modify this to be more descriptive\necho \"Committing changes...\"\ngit commit -m \"Update website content\"\n\n# Push the changes to GitHub\necho \"Pushing changes to GitHub...\"\ngit push repo_name main\n\n# Build the Quarto project\necho \"Building the Quarto website...\"\nquarto render\n\n# Sync the build output to the NGINX directory\necho \"Syncing files to the NGINX directory...\"\nsudo rsync -av --delete /home/user_name/projects/portfolio/_site/ /var/www/portfolio/\n\n# Restart NGINX server\nsudo systemctl reload nginx\n\necho \"Website published successfully.\"\n\n\n2. Making the Script Executable\n\nTo make the script executable, run the following command:\n\nchmod +x publish_website.sh\n\n\n3. Run the Script\n\nExecute the script to automate the process of updating and publishing your website.\n\n./publish_website.sh\nThis setup provides a convenient way to regularly update and publish your Quarto website with minimal manual intervention."
  },
  {
    "objectID": "projects/server/server.html#version-control-with-git-using-ssh",
    "href": "projects/server/server.html#version-control-with-git-using-ssh",
    "title": "Building a Data Science Server on Raspberry Pi",
    "section": "Version Control With git using ssh",
    "text": "Version Control With git using ssh\nOnce the workflow is working, to streamline the process, I updated my git/GitHub repository using SSH from the command line. This means you do not need to input your git username and password (key) each time you push your changes to GitHub.\nTo do this, I needed to set up SSH keys, associate them with my GitHub account, and then use Git commands to push my changes. Here’s a brief summary of the steps:\n\n1. Generate SSH Key Pair\nOpen your terminal and generate a new SSH key pair (if you haven’t already):\nssh-keygen -t rsa -b 4096 -C \"your_email@example.com\"\n# Follow the prompts to specify the file in which to save the key.\nReplace \"your_email@example.com\" with your email associated with your GitHub account. Press Enter to accept the default file location and name.\n\n\n2. Add SSH Key to SSH-Agent\nStart the SSH agent and add your SSH key:\n# Start the SSH agent\neval \"$(ssh-agent -s)\"\n\n# Add SSH key to the SSH agent\nssh-add ~/.ssh/id_rsa\nIf you saved your key to a different location, replace ~/.ssh/id_rsa with your key’s path.\n\n\n3. Add SSH Key to GitHub Account\n\nCopy the SSH key to your clipboard:\ncat ~/.ssh/id_rsa.pub | clip\nLogin to GitHub, and in the upper-right corner, click your profile photo, then click Settings.\nIn the user settings sidebar, click SSH and GPG keys.\nClick New SSH key or Add SSH key.\nIn the “Title” field, add a descriptive label for the new key, paste your key into the “Key” field.\nClick Add SSH key.\n\n\n\n4. Change Git Remote URL to SSH\nChange your repository’s remote URL from HTTPS to SSH:\n# Change to your repository's directory\ncd /path/to/your/repository\n\n# Set the remote URL to SSH\ngit remote set-url origin git@github.com:username/repository.git\nReplace username/repository.git with your GitHub username and repository name.\n\n\n5. Push Changes Using SSH\nAfter making your changes, add, commit, and push them using Git:\n# Add changes to staging\ngit add .\n\n# Commit changes\ngit commit -m \"Your commit message\"\n\n# Push changes to GitHub\ngit push origin main\nThis will use SSH for authentication, ensuring secure communication with GitHub. You can verify that SSH is being used by running git remote -v, which should show the SSH URL for origin."
  },
  {
    "objectID": "projects/server/server.html#develop-your-website-with-an-integrated-development-environment",
    "href": "projects/server/server.html#develop-your-website-with-an-integrated-development-environment",
    "title": "Building a Data Science Server on Raspberry Pi",
    "section": "Develop Your Website With An Integrated Development Environment",
    "text": "Develop Your Website With An Integrated Development Environment\nBuilding a website from the command line using SSH on a local server can be a bit tricky and slow, especially if you are not used to working with the Bash shell in the terminal.\nTo more easily develop my portfolio and preview my website as I build it, I configured Visual Studio Code - a popular code editor and Integrated Development Environment for data science - on my Thinkpad to interface with the Raspberry Pi server.\nTo install Visual Studio Code on Ubuntu and set it up for remote development with a Raspberry Pi via SSH, follow these steps:\n\nInstalling Visual Studio Code on Ubuntu\n\nUpdate Package List: Open a terminal and update your package list:\nsudo apt update\nInstall VS Code: You can install VS Code from the Ubuntu Software Center or via the command line. To install via command line, use:\nsudo apt install code\nAlternatively, you can download the .deb package from the VS Code website and install it using:\nsudo dpkg -i &lt;path-to-downloaded-deb-file&gt;\n\n\n\nSetting Up Remote Development\n\nInstall Remote Development Extension in VS Code:\n\nLaunch VS Code.\nGo to the Extensions view by clicking on the square icon on the sidebar, or press Ctrl+Shift+X.\nSearch for “Remote Development” and install the extension pack by Microsoft.\n\nSetting Up SSH Keys for Raspberry Pi (if not already done):\n\nOn your Ubuntu machine, open a terminal and create an SSH key pair (skip if you already have one):\nssh-keygen -t rsa -b 4096\nCopy the public key to your Raspberry Pi:\nssh-copy-id pi@raspberry_pi_ip\nReplace pi@raspberry_pi_ip with the username and IP address of your Raspberry Pi.\n\nConnecting to Raspberry Pi via SSH in VS Code:\n\nIn VS Code, open the Command Palette (Ctrl+Shift+P).\nType “Remote-SSH: Connect to Host…” and select it.\nEnter the SSH connection command: pi@raspberry_pi_ip.\nVS Code will connect to the Raspberry Pi. You might be prompted to select the OS type (Linux).\nOnce connected, you can open folders, edit files, and use the terminal on the Raspberry Pi remotely.\n\nWorking Remotely:\n\nWith the remote connection established, you can now work on your Raspberry Pi’s file system directly from VS Code on your Ubuntu machine.\nYou can install additional extensions, run scripts, and even debug remotely.\n\n\n\n\nNotes\n\nEnsure that SSH is enabled on your Raspberry Pi and that it is accessible from your Ubuntu machine.\nThe username pi is the default for Raspberry Pi OS; replace it with the appropriate username if you are using a different OS or have changed the default username.\nKeep your Raspberry Pi’s IP address handy for remote connections. If it’s on a dynamic IP, consider setting a static IP or using a hostname.\n\nBy following these steps, you’ll be able to efficiently develop and manage projects on your Raspberry Pi directly from your Ubuntu machine using VS Code’s powerful remote development capabilities."
  }
]